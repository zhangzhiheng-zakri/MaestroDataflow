# MaestroDataflow

MaestroDataflow æ˜¯ä¸€ä¸ªç°ä»£åŒ–çš„AIå¢å¼ºæ•°æ®å¤„ç†æ¡†æ¶ï¼Œä¸“ä¸ºé«˜æ•ˆå¤„ç†å¤šç§æ ¼å¼çš„æ•°æ®æ–‡ä»¶è€Œè®¾è®¡ã€‚å®ƒä¸ä»…æä¾›äº†ç»Ÿä¸€çš„æ¥å£æ¥å¤„ç† XLSXã€CSVã€JSONã€JSONL å’Œ Parquet æ ¼å¼çš„æ•°æ®ï¼Œè¿˜é›†æˆäº†å…ˆè¿›çš„AIåŠŸèƒ½ï¼ŒåŒ…æ‹¬å‘é‡æ•°æ®åº“ã€æ¨¡å‹ç¼“å­˜ã€æ™ºèƒ½æ•°æ®å¤„ç†æ“ä½œç¬¦ã€æ•°æ®åˆ†æä¸å¯è§†åŒ–ç­‰å…¨æ–¹ä½çš„æ•°æ®ç§‘å­¦è§£å†³æ–¹æ¡ˆã€‚

**ç‰ˆæœ¬**: 1.0.0  
**Pythonè¦æ±‚**: 3.8+  
**è®¸å¯è¯**: MIT

## ç‰¹ç‚¹

### æ ¸å¿ƒåŠŸèƒ½
- **å¤šæ ¼å¼æ”¯æŒ**ï¼šæ— ç¼å¤„ç† XLSXã€CSVã€JSONã€JSONL å’Œ Parquet æ ¼å¼çš„æ•°æ®æ–‡ä»¶
- **ç»Ÿä¸€æ¥å£**ï¼šä½¿ç”¨ä¸€è‡´çš„ API å¤„ç†ä¸åŒæ ¼å¼çš„æ•°æ®
- **ç®€å•æ˜“ç”¨**ï¼šç›´è§‚çš„æ–¹æ³•å‘½åå’Œé“¾å¼è°ƒç”¨æ”¯æŒ
- **é«˜æ•ˆå¤„ç†**ï¼šä¼˜åŒ–çš„æ•°æ®å¤„ç†æµç¨‹ï¼Œæ”¯æŒå¤§å‹æ•°æ®é›†
- **æ ¼å¼è½¬æ¢**ï¼šè½»æ¾åœ¨ä¸åŒæ ¼å¼ä¹‹é—´è½¬æ¢æ•°æ®
- **ç¼“å­˜æœºåˆ¶**ï¼šå†…ç½®ç¼“å­˜ç³»ç»Ÿï¼Œæé«˜å¤„ç†æ•ˆç‡
- **ç®¡é“å¤„ç†**ï¼šæ”¯æŒå¤æ‚çš„æ•°æ®å¤„ç†ç®¡é“å’Œæ“ä½œç¬¦

### AIå¢å¼ºåŠŸèƒ½
- **å‘é‡æ•°æ®åº“**ï¼šå†…ç½®å‘é‡å­˜å‚¨å’Œç›¸ä¼¼æ€§æœç´¢åŠŸèƒ½
- **æ¨¡å‹ç¼“å­˜**ï¼šæ™ºèƒ½æ¨¡å‹è¾“å‡ºç¼“å­˜ï¼Œæé«˜AIåº”ç”¨æ€§èƒ½
- **AIæ“ä½œç¬¦**ï¼šä¸°å¯Œçš„AIæ•°æ®å¤„ç†æ“ä½œç¬¦ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†æã€æƒ…æ„Ÿåˆ†æç­‰
- **LLMé›†æˆ**ï¼šæ”¯æŒæœ¬åœ°å’ŒAPI LLMæœåŠ¡é›†æˆ
- **æ™ºèƒ½æ•°æ®æ¸…æ´—**ï¼šåŸºäºAIçš„è‡ªåŠ¨æ•°æ®æ¸…æ´—å’Œè´¨é‡æ£€æµ‹

### æ•°æ®åˆ†æä¸å¯è§†åŒ–åŠŸèƒ½ ğŸ†•
- **ç»Ÿè®¡åˆ†æ**ï¼šå…¨é¢çš„æè¿°æ€§ç»Ÿè®¡ã€å¢é•¿ç‡è®¡ç®—ã€è¶‹åŠ¿åˆ†æ
- **æ•°æ®å¯è§†åŒ–**ï¼šæ”¯æŒçº¿å›¾ã€æŸ±çŠ¶å›¾ã€æ•£ç‚¹å›¾ã€é¥¼å›¾ã€çƒ­åŠ›å›¾ç­‰å¤šç§å›¾è¡¨ç±»å‹
- **äº¤äº’å¼ä»ªè¡¨æ¿**ï¼šåŸºäºPlotlyçš„å“åº”å¼ä»ªè¡¨æ¿ç”Ÿæˆ
- **ä¸“ä¸šæŠ¥å‘Š**ï¼šè‡ªåŠ¨ç”ŸæˆHTML/PDFæ ¼å¼çš„æ•°æ®åˆ†ææŠ¥å‘Š
- **æ¨¡æ¿ç³»ç»Ÿ**ï¼šæä¾›å¤šç§æŠ¥å‘Šæ¨¡æ¿ï¼ˆç»¼åˆæŠ¥å‘Šã€æ‰§è¡Œæ‘˜è¦ã€æŠ€æœ¯æŠ¥å‘Šï¼‰

## å®‰è£…

### åŸºç¡€å®‰è£…

```bash
pip install maestro-dataflow
```

### å®Œæ•´å®‰è£…ï¼ˆåŒ…å«æ‰€æœ‰AIä¾èµ–ï¼‰

```bash
pip install maestro-dataflow[full]
```

### å¼€å‘å®‰è£…

```bash
git clone https://github.com/maestro-dataflow/MaestroDataflow.git
cd MaestroDataflow
pip install -e .[dev,full]
```

### ä¾èµ–è¦æ±‚

- Python 3.8+
- pandas >= 1.3.0
- numpy >= 1.20.0
- openpyxl >= 3.0.0 (Excelæ–‡ä»¶æ”¯æŒ)
- å…¶ä»–ä¾èµ–è¯¦è§ `requirements.txt`

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ç”¨æ³•

```python
from maestro.utils.storage import FileStorage
from maestro.pipeline.pipeline import Pipeline
from maestro.operators.basic_ops import FilterRowsOperator, SelectColumnsOperator

# åˆ›å»ºå­˜å‚¨å®ä¾‹
storage = FileStorage(
    input_file_path="../sample_data/employees.csv",
    cache_path="../output/basic_example/cache",
    file_name_prefix="process",
    cache_type="xlsx"
)

# åˆ›å»ºç®¡é“å’Œæ“ä½œç¬¦
pipeline = Pipeline(storage=storage)
filter_op = FilterRowsOperator(condition=lambda row: row['salary'] > 50000)
select_op = SelectColumnsOperator(columns=['name', 'department', 'salary'])

# æ·»åŠ æ“ä½œç¬¦åˆ°ç®¡é“
pipeline.add_operator(filter_op)
pipeline.add_operator(select_op)

# è¿è¡Œç®¡é“
pipeline.run()

# è¯»å–å¤„ç†ç»“æœ
result_data = storage.step().read()
print(result_data)
```

### æœ€æ–°æ›´æ–°ï¼ˆè¾“å…¥ä¸å‘½åçº¦å®šï¼‰
- è¾“å…¥æ–‡ä»¶ç›®å½•ç»Ÿä¸€ä¸º `input/datasets/`ï¼Œç¤ºä¾‹è„šæœ¬ä¼šè‡ªåŠ¨é€’å½’æŸ¥æ‰¾ï¼Œä¼˜å…ˆé€‰æ‹© `.xlsx`ï¼Œå…¶æ¬¡ `.csv`ã€‚ä¼šå¿½ç•¥ä¸´æ—¶/éšè—æ–‡ä»¶ï¼ˆå¦‚ä»¥ `~$`ã€`.`ã€`._` å¼€å¤´ï¼‰ã€‚
- å¯é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®šè¾“å…¥æ–‡ä»¶ï¼š`MAESTRO_INPUT_FILE`ï¼Œä½†è·¯å¾„å¿…é¡»ä½äº `input/datasets/` å†…ã€‚
- æ ‡å‡†åŒ–æ‰“åŒ…æ—¶ç”Ÿæˆçš„ç±»åä¸ç±»æ–‡ä»¶åä½¿ç”¨è‹±æ–‡ç®€ç§°ï¼š`Dataset<ShortSlug>`ã€‚ç®€ç§°è§„åˆ™ä¸ºï¼š
  - å…ˆå°†æºæ–‡ä»¶åè½¬ä¸º ASCII slugï¼ˆç§»é™¤éå­—æ¯æ•°å­—å­—ç¬¦ï¼‰ã€‚
  - è‹¥å­˜åœ¨ PascalCase å¤§å†™åˆ†è¯ï¼Œå–æ‰€æœ‰å¤§å†™å­—æ¯ä½œä¸ºç¼©å†™ï¼ˆé•¿åº¦â‰¥3ä¼˜å…ˆï¼‰ã€‚
  - å¦åˆ™æˆªå–å‰ 10 ä¸ªå­—æ¯ï¼Œå¹¶ç¡®ä¿é¦–å­—æ¯å¤§å†™ï¼›æ— å­—æ¯åˆ™å›é€€ä¸º `Dataset`ã€‚
- é›†æˆç¤ºä¾‹å°†æ•°æ®åº“è¡¨åä¹Ÿç»Ÿä¸€ä½¿ç”¨ç±»åå½¢å¼ï¼ˆä¾‹å¦‚ `DatasetLCEC`ï¼‰ï¼Œä¸ç±»åä¿æŒä¸€è‡´ï¼Œä¾¿äºä»£ç å’Œæ•°æ®åº“å·¥å…·ç»Ÿä¸€å¼•ç”¨ï¼›ä¸­æ–‡æ˜¾ç¤ºåç§°ä¿ç•™ä¸ºæºæ–‡ä»¶åã€‚

- å¢é‡æ‰“åŒ…ï¼šæ–°å¢æ•°æ®é›†æ—¶ï¼Œæ— éœ€é‡è·‘å·²æ‰“åŒ…çš„æ•°æ®é›†ã€‚æ•´åˆç¤ºä¾‹ä»…å¤„ç†å½“å‰è¾“å…¥æ–‡ä»¶å¹¶åœ¨ `output/datasets/` ä¸‹æ–°å¢å¯¹åº”ç›®å½•å’Œç±»æ–‡ä»¶ï¼Œä¸å½±å“å·²ç”Ÿæˆçš„æ•°æ®é›†ã€‚è‹¥è¾“å‡ºç›®å½•åŒåå·²å­˜åœ¨ï¼Œé»˜è®¤ä¼šè¦†ç›–åŒåçš„ CSV/JSON/ç±»æ–‡ä»¶ï¼›å¦‚éœ€ä¿ç•™æ—§ç‰ˆæœ¬ï¼Œè¯·è°ƒæ•´æºæ–‡ä»¶åæˆ–è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„ã€‚

è¿è¡Œæ•´åˆç¤ºä¾‹ï¼ˆæ¸…æ´—â†’å…¥åº“â†’æ‰“åŒ…ï¼‰ï¼š

```bash
python -m examples.integrated_packaging_workflow
```

å¯é€‰ç¯å¢ƒå˜é‡ï¼š
- `DEEPSEEK_API_KEY`ï¼šå¯ç”¨ LLM ç”Ÿæˆæ•°æ®é›†ç®€ä»‹åŠè¾…åŠ©è‹±æ–‡ç®€ç§°ï¼›æœªè®¾ç½®æ—¶å°†ä½¿ç”¨å ä½/å›é€€é€»è¾‘ç»§ç»­æ‰§è¡Œã€‚
- `MAESTRO_INPUT_FILE`ï¼šæŒ‡å®š `input/datasets/` å†…çš„å…·ä½“æ–‡ä»¶è·¯å¾„ï¼ˆå¿…é¡»ä½äºè¯¥ç›®å½•ï¼‰ã€‚

è¾“å‡ºç»“æ„ç¤ºä¾‹ï¼š
- `dataset_dir`: `output/datasets/ä¸Šå¸‚å…¬å¸èƒ½æºæ¶ˆè€—æ•°æ®ï¼ˆ2012-2024å¹´ï¼‰`
- `data_path`: `output/datasets/ä¸Šå¸‚å…¬å¸èƒ½æºæ¶ˆè€—æ•°æ®ï¼ˆ2012-2024å¹´ï¼‰/ä¸Šå¸‚å…¬å¸èƒ½æºæ¶ˆè€—æ•°æ®ï¼ˆ2012-2024å¹´ï¼‰.csv`
- `all_column_name`: `output/datasets/ä¸Šå¸‚å…¬å¸èƒ½æºæ¶ˆè€—æ•°æ®ï¼ˆ2012-2024å¹´ï¼‰/all_column_name.json`
- `class_file`: `output/datasets/DatasetLCEC.py`
- `class_name`: `DatasetLCEC`
- ç±»æ–‡ä»¶ä¸­çš„ `name`: ä¸­æ–‡æºåç§°ï¼›`info`: è‹¥å¯ç”¨ LLMï¼Œå°†è‡ªåŠ¨ç”Ÿæˆä¸è¶…è¿‡ 120 å­—çš„ä¸­æ–‡ç®€ä»‹ã€‚

è¯´æ˜ï¼šæ‰“åŒ…æµç¨‹ä»…ç”Ÿæˆåˆ—åæ„ä¹‰ JSON æ–‡ä»¶ `all_column_name.json`ï¼Œç±»æ–‡ä»¶çš„ `columns_path` æŒ‡å‘è¯¥æ–‡ä»¶ï¼›ä¸å†ç”Ÿæˆæˆ–ä¾èµ– `column_template.json`ã€‚

### æ•°æ®åˆ†æä¸å¯è§†åŒ–ç¤ºä¾‹ ğŸ†•

```python
from maestro.pipeline.pipeline import Pipeline
from maestro.utils.storage import FileStorage
from maestro.operators.analytics_ops import DataAnalysisOperator, DataSummaryOperator
from maestro.operators.visualization_ops import ChartGeneratorOperator, DashboardGeneratorOperator
from maestro.operators.report_ops import HTMLReportGeneratorOperator

# åˆ›å»ºå­˜å‚¨å®ä¾‹
storage = FileStorage(
    input_file_path="../data/sales_data.csv",
    cache_path="../output/analytics_example/cache"
)

# åˆ›å»ºæ•°æ®åˆ†æå·¥ä½œæµ
workflow = Pipeline(storage=storage)

# æ·»åŠ æ•°æ®åˆ†æç®—å­
analysis_op = DataAnalysisOperator(
    columns_to_analyze=['é”€å”®é¢', 'åˆ©æ¶¦ç‡'],
    time_column='æ—¥æœŸ',
    include_growth_analysis=True
)

# æ·»åŠ å›¾è¡¨ç”Ÿæˆç®—å­
chart_op = ChartGeneratorOperator(
    chart_type='line',
    x_column='æ—¥æœŸ',
    y_columns=['é”€å”®é¢'],
    title='é”€å”®è¶‹åŠ¿åˆ†æ',
    output_file='sales_trend.png'
)

# æ·»åŠ ä»ªè¡¨æ¿ç”Ÿæˆç®—å­
dashboard_op = DashboardGeneratorOperator(
    dashboard_title='é”€å”®æ•°æ®ä»ªè¡¨æ¿',
    chart_configs=[
        {
            'type': 'line',
            'x_column': 'æ—¥æœŸ',
            'y_columns': ['é”€å”®é¢'],
            'title': 'é”€å”®è¶‹åŠ¿'
        },
        {
            'type': 'bar',
            'x_column': 'æœˆä»½',
            'y_columns': ['åˆ©æ¶¦ç‡'],
            'title': 'æœˆåº¦åˆ©æ¶¦ç‡'
        }
    ]
)

# æ·»åŠ æŠ¥å‘Šç”Ÿæˆç®—å­
report_op = HTMLReportGeneratorOperator(
    report_title='é”€å”®æ•°æ®åˆ†ææŠ¥å‘Š',
    output_file='sales_report.html',
    template_style='modern'
)

# æ„å»ºå·¥ä½œæµ
workflow.add_operator("analysis", analysis_op)
workflow.add_operator("chart", chart_op, depends_on=["analysis"])
workflow.add_operator("dashboard", dashboard_op, depends_on=["chart"])
workflow.add_operator("report", report_op, depends_on=["dashboard"])

# æ‰§è¡Œå·¥ä½œæµ
result = workflow.run(sales_data)
```

### AIå¢å¼ºå­˜å‚¨ç³»ç»Ÿ

```python
from maestro.utils.storage import FileStorage

# åˆ›å»ºAIå¢å¼ºçš„FileStorageå®ä¾‹
storage = FileStorage(
    input_file_path="./sample_data/employees.csv",
    cache_path="./cache",
    file_name_prefix="ai_process",
    cache_type="csv",
    enable_vector_storage=True,    # å¯ç”¨å‘é‡å­˜å‚¨
    enable_model_cache=True,       # å¯ç”¨æ¨¡å‹ç¼“å­˜
    vector_db_config={"similarity_metric": "cosine"},
    model_cache_config={
        "cache_type": "hybrid",
        "cache_config": {
            "memory": {"max_size": 100, "default_ttl": 3600},
            "disk": {"cache_dir": "./cache/model_cache", "max_size_mb": 500}
        }
    }
)

# åˆå§‹åŒ–å¹¶è¯»å–æ•°æ®
storage.step()
data = storage.read("dataframe")

# ä½¿ç”¨AIåŠŸèƒ½
import numpy as np

# æ·»åŠ å‘é‡åˆ°å‘é‡æ•°æ®åº“
vectors = np.random.rand(10, 128)  # ç¤ºä¾‹å‘é‡
metadata = [{"id": i, "text": f"sample_{i}"} for i in range(10)]
storage.add_vectors(vectors, metadata)

# æœç´¢ç›¸ä¼¼å‘é‡
query_vector = np.random.rand(128)
results = storage.search_vectors(query_vector, top_k=5)
print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸ä¼¼ç»“æœ")
```

### æ•°æ®åˆ†æä¸å¯è§†åŒ–ç®—å­ ğŸ†•
- **DataAnalysisOperator**: å…¨é¢çš„ç»Ÿè®¡åˆ†æï¼ŒåŒ…æ‹¬æè¿°æ€§ç»Ÿè®¡ã€å¢é•¿ç‡è®¡ç®—
- **DataSummaryOperator**: æ•°æ®æ‘˜è¦å’Œè´¨é‡è¯„ä¼°ï¼Œæ”¯æŒç›¸å…³æ€§åˆ†æ
- **ChartGeneratorOperator**: å¤šç§å›¾è¡¨ç±»å‹ç”Ÿæˆï¼ˆçº¿å›¾ã€æŸ±çŠ¶å›¾ã€æ•£ç‚¹å›¾ã€é¥¼å›¾ã€çƒ­åŠ›å›¾ã€ç®±çº¿å›¾ï¼‰
- **DashboardGeneratorOperator**: äº¤äº’å¼ä»ªè¡¨æ¿ç”Ÿæˆï¼Œæ”¯æŒå¤šå›¾è¡¨ç»„åˆ
- **HTMLReportGeneratorOperator**: ä¸“ä¸šHTMLæŠ¥å‘Šç”Ÿæˆï¼Œæ”¯æŒå¤šç§æ¨¡æ¿æ ·å¼
- **PDFReportGeneratorOperator**: PDFæ ¼å¼æŠ¥å‘Šç”Ÿæˆ
- **ReportTemplateOperator**: é¢„å®šä¹‰æŠ¥å‘Šæ¨¡æ¿ï¼ˆç»¼åˆæŠ¥å‘Šã€æ‰§è¡Œæ‘˜è¦ã€æŠ€æœ¯æŠ¥å‘Šï¼‰

### AIæ“ä½œç¬¦ä½¿ç”¨

```python
from maestro.operators.ai_ops import TextAnalysisOperator, SentimentAnalysisOperator
from maestro.serving.llm_serving import APILLMServing

# åˆ›å»ºLLMæœåŠ¡
llm_serving = APILLMServing(
    api_key="your_api_key",
    model_name="gpt-3.5-turbo",
    base_url="https://api.openai.com/v1"
)

# åˆ›å»ºAIæ“ä½œç¬¦
text_analysis_op = TextAnalysisOperator(
    llm_serving=llm_serving,
    analysis_type="keyword_extraction",
    target_column="content"
)

sentiment_op = SentimentAnalysisOperator(
    llm_serving=llm_serving,
    target_column="content",
    output_column="sentiment"
)

# åœ¨ç®¡é“ä¸­ä½¿ç”¨AIæ“ä½œç¬¦
pipeline = Pipeline(storage=storage)
pipeline.add_operator(text_analysis_op)
pipeline.add_operator(sentiment_op)
pipeline.run()
```

#### APIå¯†é’¥é…ç½®ä¸å®‰å…¨
- å¼ºçƒˆå»ºè®®é€šè¿‡ç¯å¢ƒå˜é‡æ³¨å…¥å¯†é’¥ï¼Œé¿å…å°†çœŸå®å¯†é’¥å†™å…¥ä»£ç æˆ–æäº¤åˆ°ç‰ˆæœ¬åº“ã€‚
- æ”¯æŒçš„ç¯å¢ƒå˜é‡åŒ…æ‹¬ï¼š`OPENAI_API_KEY`ã€`DEEPSEEK_API_KEY`ã€`AZURE_OPENAI_API_KEY`ã€‚

æ¨èç”¨æ³•ç¤ºä¾‹ï¼š

```python
import os
from maestro.serving.llm_serving import APILLMServing

# ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–å¯†é’¥
api_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("æœªè®¾ç½® API å¯†é’¥ï¼Œè¯·é…ç½® DEEPSEEK_API_KEY æˆ– OPENAI_API_KEY")

llm_serving = APILLMServing(
    api_key=api_key,
    model_name="gpt-3.5-turbo",
    base_url="https://api.openai.com/v1"
)
```

åœ¨ Windows ç»ˆç«¯è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
- ä¸´æ—¶å½“å‰ä¼šè¯ï¼š`$env:DEEPSEEK_API_KEY="ä½ çš„å¯†é’¥"`
- æ°¸ä¹…ï¼ˆé‡å¯ç»ˆç«¯åç”Ÿæ•ˆï¼‰ï¼š`setx DEEPSEEK_API_KEY "ä½ çš„å¯†é’¥"`

å¦‚æ›¾è¯¯æäº¤çœŸå®å¯†é’¥ï¼Œè¯·åœ¨å¯¹åº”å¹³å°åŠæ—¶â€œæ—‹è½¬/é‡ç½®å¯†é’¥â€ã€‚

### ç›´æ¥ä½¿ç”¨å­˜å‚¨ç³»ç»Ÿ

```python
from maestro.utils.storage import FileStorage

# åˆ›å»ºFileStorageå®ä¾‹
storage = FileStorage(
    input_file_path="path/to/your/data.xlsx",  # æ”¯æŒxlsxã€csvã€jsonã€jsonl
    cache_path="./cache",                       # ç¼“å­˜ç›®å½•
    file_name_prefix="example",                 # ç¼“å­˜æ–‡ä»¶åå‰ç¼€
    cache_type="xlsx"                           # è¾“å‡ºæ–‡ä»¶ç±»å‹
)

# åˆå§‹åŒ–å¹¶è¯»å–æ•°æ®
storage.step()
data = storage.read("dataframe")  # æˆ– "dict"

# å¤„ç†æ•°æ®
processed_data = data[data['score'] > 80]

# ä¿å­˜å¤„ç†ç»“æœ
result_path = storage.write(processed_data)
print(f"ç»“æœå·²ä¿å­˜è‡³: {result_path}")
```

### æ ¼å¼è½¬æ¢

```python
# ä»XLSXè¯»å–
storage_in = FileStorage(
    input_file_path="data.xlsx",
    cache_path="./cache",
    file_name_prefix="original",
    cache_type="xlsx"
)

# åˆå§‹åŒ–å¹¶è¯»å–æ•°æ®
storage_in.step()
data = storage_in.read("dataframe")

# è½¬æ¢ä¸ºJSONæ ¼å¼ä¿å­˜
storage_out = FileStorage(
    input_file_path="dummy.xlsx",  # ä¸ä¼šå®é™…ä½¿ç”¨æ­¤æ–‡ä»¶
    cache_path="./cache",
    file_name_prefix="converted",
    cache_type="json"
)

json_path = storage_out.write(data)
print(f"å·²è½¬æ¢ä¸ºJSON: {json_path}")
```

## æ”¯æŒçš„æ–‡ä»¶ç±»å‹

- **XLSX**: Excelæ–‡ä»¶æ ¼å¼
- **CSV**: é€—å·åˆ†éš”å€¼æ–‡ä»¶
- **JSON**: JavaScriptå¯¹è±¡è¡¨ç¤ºæ³•
- **JSONL**: æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
- **Parquet**: é«˜æ•ˆçš„åˆ—å¼å­˜å‚¨æ ¼å¼
- **Pickle**: Pythonå¯¹è±¡åºåˆ—åŒ–æ ¼å¼

## æ ¸å¿ƒåŠŸèƒ½

MaestroDataflow æä¾›äº†ä¸°å¯Œçš„æ•°æ®å¤„ç†åŠŸèƒ½ï¼š

### å­˜å‚¨ç³»ç»Ÿ
- **FileStorage**: æ–‡ä»¶å­˜å‚¨ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼Œé›†æˆAIåŠŸèƒ½
- **DBStorage**: æ•°æ®åº“å­˜å‚¨ç³»ç»Ÿï¼Œæ”¯æŒSQLiteç­‰æ•°æ®åº“
- **VectorStorage**: å‘é‡æ•°æ®åº“å­˜å‚¨ï¼Œæ”¯æŒç›¸ä¼¼æ€§æœç´¢

### åŸºç¡€æ“ä½œç¬¦
- **FilterRowsOperator**: æ ¹æ®æ¡ä»¶ç­›é€‰æ•°æ®è¡Œ
- **SelectColumnsOperator**: é€‰æ‹©ç‰¹å®šåˆ—
- **MapRowsOperator**: å¯¹æ•°æ®è¡Œåº”ç”¨è‡ªå®šä¹‰å‡½æ•°
- **AggregateOperator**: æ•°æ®èšåˆæ“ä½œ
- **SortOperator**: æ•°æ®æ’åºæ“ä½œ

### AIæ“ä½œç¬¦
- **TextAnalysisOperator**: æ–‡æœ¬åˆ†æå’Œå…³é”®è¯æå–
- **SentimentAnalysisOperator**: æƒ…æ„Ÿåˆ†æ
- **DataCleaningOperator**: æ™ºèƒ½æ•°æ®æ¸…æ´—
- **EmbeddingOperator**: æ–‡æœ¬å‘é‡åŒ–
- **SimilaritySearchOperator**: ç›¸ä¼¼æ€§æœç´¢

### LLMæœåŠ¡
- **APILLMServing**: APIæ–¹å¼è°ƒç”¨LLMæœåŠ¡ï¼ˆOpenAIã€Azureç­‰ï¼‰
- **LocalLLMServing**: æœ¬åœ°LLMæ¨¡å‹æœåŠ¡
- **EnhancedLLMServing**: å¢å¼ºçš„LLMæœåŠ¡ï¼Œæ”¯æŒç¼“å­˜å’Œé‡è¯•

### ç®¡é“ç³»ç»Ÿ
- **Pipeline**: æ•°æ®å¤„ç†ç®¡é“ï¼Œæ”¯æŒé“¾å¼æ“ä½œ
- **BatchPipeline**: æ‰¹å¤„ç†ç®¡é“ï¼Œæ”¯æŒå¤§æ•°æ®é›†å¤„ç†
- **æ­¥éª¤ç®¡ç†**: è‡ªåŠ¨ç®¡ç†å¤„ç†æ­¥éª¤å’Œç¼“å­˜
- **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶

## é¡¹ç›®ç»“æ„

```
MaestroDataflow/
â”œâ”€â”€ maestro/                    # æ ¸å¿ƒæ¡†æ¶ä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                   # æ ¸å¿ƒç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py            # åŸºç¡€ç±»å®šä¹‰
â”‚   â”‚   â””â”€â”€ pipeline.py        # ç®¡é“ç³»ç»Ÿ
â”‚   â”œâ”€â”€ utils/                  # å·¥å…·æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ storage.py         # å­˜å‚¨ç³»ç»Ÿ
â”‚   â”‚   â””â”€â”€ ai_utils.py        # AIå·¥å…·
â”‚   â”œâ”€â”€ operators/              # æ“ä½œç¬¦
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_ops.py        # åŸºç¡€æ“ä½œç¬¦
â”‚   â”‚   â”œâ”€â”€ io_ops.py          # è¾“å…¥è¾“å‡ºæ“ä½œç¬¦
â”‚   â”‚   â”œâ”€â”€ transform_ops.py   # æ•°æ®è½¬æ¢æ“ä½œç¬¦
â”‚   â”‚   â”œâ”€â”€ ai_ops.py          # AIæ“ä½œç¬¦
â”‚   â”‚   â”œâ”€â”€ analysis_ops.py    # æ•°æ®åˆ†ææ“ä½œç¬¦
â”‚   â”‚   â””â”€â”€ visualization_ops.py # å¯è§†åŒ–æ“ä½œç¬¦
â”‚   â””â”€â”€ services/               # æœåŠ¡æ¨¡å—
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ llm_service.py     # LLMæœåŠ¡
â”‚       â””â”€â”€ vector_service.py  # å‘é‡æœåŠ¡
â”œâ”€â”€ examples/                   # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ README_AI_OPERATORS.md
â”‚   â”œâ”€â”€ basic_pipeline_example.py
â”‚   â”œâ”€â”€ ai_pipeline_example.py
â”‚   â”œâ”€â”€ digital_economy_pipeline_example.py
â”‚   â””â”€â”€ visualization_example.py
â”œâ”€â”€ test/                       # æµ‹è¯•ä»£ç 
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ test_storage.py
â”‚   â”œâ”€â”€ test_operators.py
â”‚   â”œâ”€â”€ test_ai_features.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ sample_data/                # ç¤ºä¾‹æ•°æ®
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ employees.csv
â”‚   â”œâ”€â”€ sales_data.json
â”‚   â””â”€â”€ ä¸­å›½æ•°å­—ç»æµå‘å±•æ•°æ®ï¼ˆ2005-2023å¹´ï¼‰.xlsx
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”œâ”€â”€ output/                     # è¾“å‡ºç›®å½•
â”œâ”€â”€ setup.py                    # å®‰è£…é…ç½®
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                   # é¡¹ç›®è¯´æ˜
```

## ç¤ºä¾‹

### åŸºç¡€ç¤ºä¾‹

æŸ¥çœ‹ `examples/` ç›®å½•ä¸­çš„ç¤ºä¾‹ä»£ç ï¼š

- **basic_pipeline_example.py** - åŸºç¡€æ•°æ®å¤„ç†ç®¡é“
- **ai_pipeline_example.py** - AIå¢å¼ºæ•°æ®å¤„ç†
- **digital_economy_pipeline_example.py** - æ•°å­—ç»æµæ•°æ®åˆ†æ
- **visualization_example.py** - æ•°æ®å¯è§†åŒ–ç¤ºä¾‹

### è¿è¡Œç¤ºä¾‹

```bash
# è¿è¡ŒåŸºç¡€ç®¡é“ç¤ºä¾‹
python examples/basic_pipeline_example.py

# è¿è¡ŒAIç®¡é“ç¤ºä¾‹
python examples/ai_pipeline_example.py

# è¿è¡Œæ•°å­—ç»æµåˆ†æç¤ºä¾‹
python examples/digital_economy_pipeline_example.py
```

## æµ‹è¯•

è¿è¡Œæµ‹è¯•å¥—ä»¶ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest test/

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
python -m pytest test/test_storage.py

# æ˜¾ç¤ºæµ‹è¯•è¦†ç›–ç‡
python -m pytest test/ --cov=maestro --cov-report=html
```

è¯¦ç»†æµ‹è¯•è¯´æ˜è¯·å‚è€ƒ `test/README.md`ã€‚

## è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿ç¤¾åŒºè´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## è”ç³»æ–¹å¼

- é¡¹ç›®ä¸»é¡µ: https://github.com/maestro-dataflow/MaestroDataflow
- é—®é¢˜åé¦ˆ: https://github.com/maestro-dataflow/MaestroDataflow/issues
- é‚®ç®±: maestro@dataflow.ai

## æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-01-15)
- ğŸ‰ é¦–æ¬¡å‘å¸ƒ
- âœ¨ æ”¯æŒå¤šç§æ•°æ®æ ¼å¼ (XLSX, CSV, JSON, JSONL, Parquet)
- ğŸ¤– é›†æˆAIåŠŸèƒ½ (å‘é‡æ•°æ®åº“, æ¨¡å‹ç¼“å­˜, AIæ“ä½œç¬¦)
- ğŸ“Š æ•°æ®åˆ†æä¸å¯è§†åŒ–åŠŸèƒ½
- ğŸ”§ å®Œæ•´çš„ç®¡é“ç³»ç»Ÿ
- ğŸ“š ä¸°å¯Œçš„ç¤ºä¾‹å’Œæ–‡æ¡£