"""
MaestroDataflow ç»¼åˆAIå·¥ä½œæµç¤ºä¾‹
å±•ç¤ºå®Œæ•´çš„ç«¯åˆ°ç«¯AIæ•°æ®å¤„ç†æµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€AIåˆ†æã€çŸ¥è¯†åº“æ„å»ºå’Œæ™ºèƒ½é—®ç­”
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging
import json
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å¯¼å…¥MaestroDataflowç»„ä»¶
from maestro.pipeline.pipeline import Pipeline
from maestro.utils.storage import FileStorage
from maestro.serving.enhanced_llm_serving import EnhancedLLMServing, LocalLLMServing
from maestro.core.prompt import DIYPromptABC, StandardPrompt

# å¯¼å…¥AIæ“ä½œç¬¦
from maestro.operators.ai_ops import (
    AutoDataCleaner, SmartAnnotator, FeatureEngineer,
    EmbeddingGenerator, KnowledgeBaseBuilder, RAGOperator, RAGRetriever,
    TextSummarizer, TextClassifier, PromptedGenerator
)


class ComprehensiveAIWorkflow:
    """
    ç»¼åˆAIå·¥ä½œæµç±»
    å®ç°å®Œæ•´çš„AIæ•°æ®å¤„ç†ç®¡é“
    """

    def __init__(self, base_path="../output/comprehensive_ai_workflow"):
        """
        åˆå§‹åŒ–ç»¼åˆAIå·¥ä½œæµ

        Args:
            base_path: åŸºç¡€è·¯å¾„
        """
        self.base_path = base_path
        self.setup_environment()

    def setup_environment(self):
        """è®¾ç½®å·¥ä½œç¯å¢ƒ"""
        logger.info("ğŸš€ è®¾ç½®ç»¼åˆAIå·¥ä½œæµç¯å¢ƒ...")

        # åˆ›å»ºç›®å½•
        os.makedirs(self.base_path, exist_ok=True)
        os.makedirs(f"{self.base_path}/data", exist_ok=True)
        os.makedirs(f"{self.base_path}/results", exist_ok=True)
        os.makedirs(f"{self.base_path}/reports", exist_ok=True)

        # åˆ›å»ºä¸€ä¸ªç©ºçš„ç¤ºä¾‹æ•°æ®æ–‡ä»¶ï¼Œä»¥ä¾¿FileStorageå¯ä»¥åˆå§‹åŒ–
        sample_data_path = f"{self.base_path}/data/sample_data.json"
        if not os.path.exists(sample_data_path):
            with open(sample_data_path, 'w', encoding='utf-8') as f:
                json.dump([], f)  # åˆ›å»ºç©ºçš„JSONæ•°ç»„

        # åˆ›å»ºå­˜å‚¨å®ä¾‹
        self.storage = FileStorage(
            input_file_path=sample_data_path,
            cache_path=f"{self.base_path}/cache",
            cache_type="csv",  # è®¾ç½®ä¸ºCSVæ ¼å¼
            enable_vector_storage=True,
            enable_model_cache=True,
            vector_db_config={"similarity_metric": "cosine"},
            model_cache_config={
                "cache_type": "hybrid",
                "cache_config": {
                    "memory": {"max_size": 100, "default_ttl": 3600},
                    "disk": {
                        "cache_dir": f"{self.base_path}/cache/model_cache",
                        "max_size_mb": 500,
                        "default_ttl": 86400
                    }
                }
            }
        )

        # åˆ›å»ºLLMæœåŠ¡
        try:
            self.llm_serving = LocalLLMServing(
                model_name="microsoft/DialoGPT-medium",
                device="cpu"
            )
            logger.info("âœ… ä½¿ç”¨æœ¬åœ°LLMæ¨¡å‹")
        except Exception as e:
            logger.warning(f"æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            from maestro.serving.llm_serving import APILLMServing
            self.llm_serving = APILLMServing(
                api_url="https://api.openai.com/v1/chat/completions",
                api_key="your-api-key-here",  # è¯·æ›¿æ¢ä¸ºå®é™…çš„APIå¯†é’¥
                model_name="gpt-3.5-turbo",
                api_type="openai"
            )
            logger.info("âœ… ä½¿ç”¨API LLMæœåŠ¡")

        # åˆ›å»ºç®¡é“
        self.workflow = Pipeline("Comprehensive_AI_Pipeline")

        logger.info("âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ")

    def generate_sample_data(self):
        """ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†"""
        logger.info("ğŸ“Š ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†...")

        # ç”Ÿæˆå®¢æˆ·åé¦ˆæ•°æ®
        np.random.seed(42)

        # äº§å“ç±»åˆ«
        products = ["æ™ºèƒ½æ‰‹æœº", "ç¬”è®°æœ¬ç”µè„‘", "å¹³æ¿ç”µè„‘", "æ™ºèƒ½æ‰‹è¡¨", "è€³æœº"]

        # ç”Ÿæˆåé¦ˆæ–‡æœ¬
        positive_comments = [
            "è¿™ä¸ªäº§å“çœŸçš„å¾ˆæ£’ï¼Œè´¨é‡å¾ˆå¥½ï¼Œæ¨èè´­ä¹°ï¼",
            "ä½¿ç”¨ä½“éªŒéå¸¸å¥½ï¼ŒåŠŸèƒ½å¼ºå¤§ï¼Œå€¼å¾—æ‹¥æœ‰ã€‚",
            "è®¾è®¡ç²¾ç¾ï¼Œæ€§èƒ½å‡ºè‰²ï¼Œéå¸¸æ»¡æ„è¿™æ¬¡è´­ä¹°ã€‚",
            "è´¨é‡è¶…å‡ºé¢„æœŸï¼Œå®¢æœæ€åº¦ä¹Ÿå¾ˆå¥½ï¼Œäº”æ˜Ÿå¥½è¯„ï¼",
            "äº§å“åŠŸèƒ½é½å…¨ï¼Œä½¿ç”¨ç®€å•ï¼Œå¼ºçƒˆæ¨èç»™å¤§å®¶ã€‚"
        ]

        negative_comments = [
            "äº§å“è´¨é‡ä¸€èˆ¬ï¼Œä¸å¤ªæ»¡æ„ï¼Œæœ‰å¾…æ”¹è¿›ã€‚",
            "ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œå¸Œæœ›èƒ½å¤Ÿè§£å†³ã€‚",
            "ä»·æ ¼åé«˜ï¼Œæ€§ä»·æ¯”ä¸æ˜¯å¾ˆå¥½ï¼Œä¸å¤ªæ¨èã€‚",
            "äº§å“æœ‰ç¼ºé™·ï¼Œå®¢æœå¤„ç†ä¸åŠæ—¶ï¼Œæ¯”è¾ƒå¤±æœ›ã€‚",
            "åŠŸèƒ½ä¸å¦‚æè¿°çš„é‚£ä¹ˆå¥½ï¼Œæœ‰äº›å¤¸å¤§å®£ä¼ ã€‚"
        ]

        neutral_comments = [
            "äº§å“è¿˜å¯ä»¥ï¼ŒåŸºæœ¬æ»¡è¶³éœ€æ±‚ï¼Œä¸­è§„ä¸­çŸ©ã€‚",
            "ä½¿ç”¨æ„Ÿå—ä¸€èˆ¬ï¼Œæ²¡æœ‰ç‰¹åˆ«çªå‡ºçš„åœ°æ–¹ã€‚",
            "è´¨é‡è¿˜è¡Œï¼Œä½†ä¹Ÿæ²¡æœ‰ä»€ä¹ˆæƒŠå–œï¼Œæ™®é€šæ°´å¹³ã€‚",
            "äº§å“åŠŸèƒ½åŸºæœ¬å¤Ÿç”¨ï¼Œä»·æ ¼ä¹Ÿç®—åˆç†ã€‚",
            "æ•´ä½“ä½“éªŒè¿˜å¯ä»¥ï¼Œæœ‰ä¼˜ç‚¹ä¹Ÿæœ‰ä¸è¶³ã€‚"
        ]

        # ç”Ÿæˆæ•°æ®
        data_size = 200
        data = []

        for i in range(data_size):
            # éšæœºé€‰æ‹©äº§å“å’Œæƒ…æ„Ÿ
            product = np.random.choice(products)
            sentiment_type = np.random.choice(["positive", "negative", "neutral"], p=[0.5, 0.3, 0.2])

            if sentiment_type == "positive":
                comment = np.random.choice(positive_comments)
                rating = np.random.randint(4, 6)
            elif sentiment_type == "negative":
                comment = np.random.choice(negative_comments)
                rating = np.random.randint(1, 3)
            else:
                comment = np.random.choice(neutral_comments)
                rating = np.random.randint(3, 4)

            # æ·»åŠ ä¸€äº›å™ªå£°æ•°æ®
            if np.random.random() < 0.1:  # 10%çš„æ•°æ®æœ‰é—®é¢˜
                if np.random.random() < 0.5:
                    comment = ""  # ç©ºè¯„è®º
                else:
                    rating = None  # ç¼ºå¤±è¯„åˆ†

            # ç”Ÿæˆæ—¶é—´æˆ³
            days_ago = np.random.randint(0, 365)
            timestamp = datetime.now() - timedelta(days=days_ago)

            data.append({
                "id": f"review_{i+1:03d}",
                "product": product,
                "comment": comment,
                "rating": rating,
                "timestamp": timestamp,
                "user_id": f"user_{np.random.randint(1, 100):03d}",
                "purchase_amount": np.random.uniform(100, 5000),
                "is_verified": np.random.choice([True, False], p=[0.8, 0.2])
            })

        # åˆ›å»ºDataFrameå¹¶ä¿å­˜
        df = pd.DataFrame(data)
        print(f"ç”Ÿæˆçš„æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"æ•°æ®åˆ—: {df.columns.tolist()}")
        print(f"å‰5è¡Œæ•°æ®:\n{df.head()}")
        
        # ç›´æ¥ä¿å­˜åˆ°step 0ï¼Œè¿™æ ·AutoDataCleanerå°±èƒ½è¯»å–åˆ°
        file_path = self.storage._get_cache_file_path(0)
        df.to_csv(file_path, index=False)
        print(f"æ•°æ®å·²ä¿å­˜åˆ°: {file_path}")

        logger.info(f"âœ… ç”Ÿæˆäº† {len(df)} æ¡å®¢æˆ·åé¦ˆæ•°æ®")
        return df

    def step1_data_cleaning(self):
        """æ­¥éª¤1: æ•°æ®æ¸…æ´—"""
        logger.info("ğŸ§¹ æ­¥éª¤1: æ‰§è¡Œæ•°æ®æ¸…æ´—...")

        # åˆ›å»ºæ•°æ®æ¸…æ´—å™¨
        cleaner = AutoDataCleaner(
            llm_serving=self.llm_serving,
            cleaning_strategies=["remove_duplicates", "handle_missing", "standardize_format"],
            confidence_threshold=0.8,
            generate_report=True
        )

        # æ‰§è¡Œæ¸…æ´—
        result = cleaner.run(
            self.storage,
            input_path="raw_customer_feedback",
            output_path="cleaned_feedback"
        )

        logger.info(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {result['original_shape']} â†’ {result['final_shape']}")
        return result

    def step2_intelligent_annotation(self):
        """æ­¥éª¤2: æ™ºèƒ½æ ‡æ³¨"""
        logger.info("ğŸ·ï¸ æ­¥éª¤2: æ‰§è¡Œæ™ºèƒ½æ ‡æ³¨...")

        # æƒ…æ„Ÿåˆ†ææ ‡æ³¨
        sentiment_annotator = SmartAnnotator(
            llm_serving=self.llm_serving,
            annotation_type="sentiment",
            target_column="comment",
            output_column="ai_sentiment",
            batch_size=5
        )

        result1 = sentiment_annotator.run(
            self.storage,
            input_path="cleaned_feedback",
            output_path="sentiment_annotated"
        )

        # äº§å“ç±»åˆ«æ ‡æ³¨
        category_annotator = SmartAnnotator(
            llm_serving=self.llm_serving,
            annotation_type="classification",
            target_column="comment",
            output_column="comment_category",
            categories=["åŠŸèƒ½", "è´¨é‡", "ä»·æ ¼", "æœåŠ¡", "å…¶ä»–"],
            batch_size=5
        )

        result2 = category_annotator.run(
            self.storage,
            input_path="sentiment_annotated",
            output_path="fully_annotated"
        )

        logger.info(f"âœ… æ™ºèƒ½æ ‡æ³¨å®Œæˆ: æƒ…æ„Ÿåˆ†æ + ç±»åˆ«åˆ†ç±»")
        return result1, result2

    def step3_feature_engineering(self):
        """æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹"""
        logger.info("âš™ï¸ æ­¥éª¤3: æ‰§è¡Œç‰¹å¾å·¥ç¨‹...")

        # åˆ›å»ºç‰¹å¾å·¥ç¨‹å™¨
        feature_engineer = FeatureEngineer(
            llm_serving=self.llm_serving,
            feature_types=["statistical", "temporal", "text", "categorical"],
            target_column="rating",
            max_features=30
        )

        result = feature_engineer.run(
            self.storage,
            input_path="fully_annotated",
            output_path="engineered_features"
        )

        logger.info(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ: {result['original_feature_count']} â†’ {result['final_feature_count']} ç‰¹å¾")
        return result

    def step4_text_summarization(self):
        """æ­¥éª¤4: æ–‡æœ¬æ‘˜è¦ç”Ÿæˆ"""
        logger.info("ğŸ“„ æ­¥éª¤4: ç”Ÿæˆæ–‡æœ¬æ‘˜è¦...")

        # æŒ‰äº§å“åˆ†ç»„ç”Ÿæˆæ‘˜è¦
        data = self.storage.read()

        summaries = []
        for product in data['product'].unique():
            product_data = data[data['product'] == product]
            product_comments = product_data['comment'].dropna().tolist()

            if len(product_comments) > 0:
                # åˆå¹¶è¯„è®º
                combined_text = " ".join(product_comments[:10])  # å–å‰10æ¡è¯„è®º

                # åˆ›å»ºæ‘˜è¦å™¨
                summarizer = TextSummarizer(
                    llm_serving=self.llm_serving,
                    input_column="text",
                    max_length=100
                )

                # ç”Ÿæˆæ‘˜è¦
                temp_df = pd.DataFrame({"text": [combined_text]})
                self.storage.step().write(temp_df)

                summary_result = summarizer.run(
                    self.storage,
                    input_path=f"temp_text_{product}",
                    output_path=f"summary_{product}"
                )

                # è¯»å–æ‘˜è¦ç»“æœ
                summary_data = self.storage.read()
                summary_text = summary_data.iloc[0]['summary'] if len(summary_data) > 0 else "æ— æ³•ç”Ÿæˆæ‘˜è¦"

                summaries.append({
                    "product": product,
                    "comment_count": len(product_comments),
                    "summary": summary_text,
                    "avg_rating": product_data['rating'].mean()
                })

        # ä¿å­˜æ‘˜è¦ç»“æœ
        summary_df = pd.DataFrame(summaries)
        self.storage.step().write(summary_df)

        logger.info(f"âœ… ç”Ÿæˆäº† {len(summaries)} ä¸ªäº§å“æ‘˜è¦")
        return summaries

    def step5_knowledge_base_construction(self):
        """æ­¥éª¤5: çŸ¥è¯†åº“æ„å»º"""
        logger.info("ğŸ§  æ­¥éª¤5: æ„å»ºçŸ¥è¯†åº“...")

        # å‡†å¤‡çŸ¥è¯†åº“æ–‡æ¡£
        data = self.storage.read()

        # åˆ›å»ºçŸ¥è¯†æ–‡æ¡£
        knowledge_docs = []
        for _, row in data.iterrows():
            if pd.notna(row['comment']) and row['comment'].strip():
                doc = f"äº§å“: {row['product']}, è¯„è®º: {row['comment']}, è¯„åˆ†: {row['rating']}, æƒ…æ„Ÿ: {row.get('ai_sentiment', 'æœªçŸ¥')}"
                knowledge_docs.append({"document": doc, "source": row['id']})

        kb_df = pd.DataFrame(knowledge_docs)
        self.storage.step().write(kb_df)

        # æ„å»ºçŸ¥è¯†åº“
        kb_builder = KnowledgeBaseBuilder(
            chunk_size=200,
            chunk_overlap=50,
            text_column="document"
        )

        result = kb_builder.run(
            self.storage,
            input_path="knowledge_documents",
            output_path="knowledge_base"
        )

        logger.info(f"âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆ: {result['total_chunks']} ä¸ªçŸ¥è¯†å—")
        return result

    def step6_rag_system_setup(self):
        """æ­¥éª¤6: RAGç³»ç»Ÿè®¾ç½®"""
        logger.info("ğŸ” æ­¥éª¤6: è®¾ç½®RAGé—®ç­”ç³»ç»Ÿ...")

        # åˆ›å»ºRAGæ£€ç´¢å™¨
        retriever = RAGRetriever(
            top_k=5,
            similarity_threshold=0.3
        )

        # åˆ›å»ºRAGæ“ä½œç¬¦
        rag_operator = RAGOperator(
            llm_serving=self.llm_serving,
            query_column="query",
            max_context_length=1000,
            include_sources=True
        )

        self.rag_operator = rag_operator
        self.retriever = retriever

        logger.info("âœ… RAGé—®ç­”ç³»ç»Ÿè®¾ç½®å®Œæˆ")
        return rag_operator

    def step7_interactive_qa(self):
        """æ­¥éª¤7: äº¤äº’å¼é—®ç­”"""
        logger.info("ğŸ’¬ æ­¥éª¤7: äº¤äº’å¼é—®ç­”æ¼”ç¤º...")

        # é¢„è®¾é—®é¢˜
        questions = [
            "ç”¨æˆ·å¯¹æ™ºèƒ½æ‰‹æœºçš„è¯„ä»·å¦‚ä½•ï¼Ÿ",
            "å“ªä¸ªäº§å“çš„è¯„åˆ†æœ€é«˜ï¼Ÿ",
            "ç”¨æˆ·ä¸»è¦å…³å¿ƒä»€ä¹ˆé—®é¢˜ï¼Ÿ",
            "æœ‰å“ªäº›è´Ÿé¢åé¦ˆï¼Ÿ",
            "äº§å“è´¨é‡æ–¹é¢çš„è¯„ä»·æ€ä¹ˆæ ·ï¼Ÿ"
        ]

        qa_results = []

        for question in questions:
            logger.info(f"ğŸ¤” é—®é¢˜: {question}")

            # å‡†å¤‡æŸ¥è¯¢
            query_df = pd.DataFrame({"query": [question]})
            self.storage.step().write(query_df)

            # æ‰§è¡ŒRAGæŸ¥è¯¢
            result = self.rag_operator.run(
                self.storage,
                query_path="current_query",
                knowledge_base_path="knowledge_base",
                output_path="current_answer"
            )

            # è¯»å–ç­”æ¡ˆ
            answer_data = self.storage.read()
            answer = answer_data.iloc[0]['response'] if len(answer_data) > 0 else "æ— æ³•ç”Ÿæˆç­”æ¡ˆ"

            qa_results.append({
                "question": question,
                "answer": answer,
                "timestamp": datetime.now()
            })

            logger.info(f"ğŸ’¡ ç­”æ¡ˆ: {answer[:100]}...")

        # ä¿å­˜é—®ç­”ç»“æœ
        qa_df = pd.DataFrame(qa_results)
        self.storage.step().write(qa_df)

        logger.info(f"âœ… å®Œæˆ {len(questions)} ä¸ªé—®é¢˜çš„é—®ç­”")
        return qa_results

    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")

        try:
            # è¯»å–å„é˜¶æ®µæ•°æ®
            raw_data = self.storage.read()
            cleaned_data = self.storage.read()
            annotated_data = self.storage.read()
            engineered_data = self.storage.read()
            summaries = self.storage.read()
            qa_results = self.storage.read()

            # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
            report = {
                "workflow_summary": {
                    "execution_time": datetime.now().isoformat(),
                    "total_steps": 7,
                    "data_processing_pipeline": [
                        "æ•°æ®æ¸…æ´—", "æ™ºèƒ½æ ‡æ³¨", "ç‰¹å¾å·¥ç¨‹",
                        "æ–‡æœ¬æ‘˜è¦", "çŸ¥è¯†åº“æ„å»º", "RAGç³»ç»Ÿ", "äº¤äº’é—®ç­”"
                    ]
                },
                "data_statistics": {
                    "raw_records": len(raw_data),
                    "cleaned_records": len(cleaned_data),
                    "annotated_records": len(annotated_data),
                    "final_features": len(engineered_data.columns),
                    "product_summaries": len(summaries),
                    "qa_pairs": len(qa_results)
                },
                "quality_metrics": {
                    "data_completeness": (1 - annotated_data.isnull().sum().sum() / (annotated_data.shape[0] * annotated_data.shape[1])) * 100,
                    "sentiment_distribution": annotated_data['ai_sentiment'].value_counts().to_dict() if 'ai_sentiment' in annotated_data.columns else {},
                    "average_rating": annotated_data['rating'].mean() if 'rating' in annotated_data.columns else 0,
                    "product_coverage": annotated_data['product'].nunique() if 'product' in annotated_data.columns else 0
                },
                "ai_capabilities_used": [
                    "è‡ªåŠ¨æ•°æ®æ¸…æ´—", "æ™ºèƒ½æƒ…æ„Ÿåˆ†æ", "æ–‡æœ¬åˆ†ç±»",
                    "ç‰¹å¾å·¥ç¨‹", "æ–‡æœ¬æ‘˜è¦", "å‘é‡æ£€ç´¢", "çŸ¥è¯†é—®ç­”"
                ],
                "system_performance": {
                    "cache_stats": self.storage.get_cache_stats() if hasattr(self.storage, 'get_cache_stats') else {},
                    "vector_stats": self.storage.get_vector_stats() if hasattr(self.storage, 'get_vector_stats') else {}
                }
            }

            # ä¿å­˜æŠ¥å‘Š
            report_path = f"{self.base_path}/reports/comprehensive_report.json"
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2, default=str)

            logger.info(f"âœ… ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
            return report

        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {"error": str(e)}

    def run_complete_workflow(self):
        """è¿è¡Œå®Œæ•´çš„å·¥ä½œæµ"""
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œç»¼åˆAIå·¥ä½œæµ...")

        try:
            # ç”Ÿæˆç¤ºä¾‹æ•°æ®
            self.generate_sample_data()

            # æ‰§è¡Œå„ä¸ªæ­¥éª¤
            step1_result = self.step1_data_cleaning()
            step2_result = self.step2_intelligent_annotation()
            step3_result = self.step3_feature_engineering()
            step4_result = self.step4_text_summarization()
            step5_result = self.step5_knowledge_base_construction()
            step6_result = self.step6_rag_system_setup()
            step7_result = self.step7_interactive_qa()

            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            final_report = self.generate_comprehensive_report()

            logger.info("ğŸ‰ ç»¼åˆAIå·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")

            # æ‰“å°æ‘˜è¦
            print("\n" + "="*60)
            print("ğŸ¯ MaestroDataflow ç»¼åˆAIå·¥ä½œæµæ‰§è¡Œæ‘˜è¦")
            print("="*60)
            print(f"ğŸ“Š å¤„ç†æ•°æ®é‡: {final_report.get('data_statistics', {}).get('raw_records', 0)} æ¡è®°å½•")
            print(f"ğŸ§¹ æ•°æ®æ¸…æ´—: å®Œæˆ")
            print(f"ğŸ·ï¸ æ™ºèƒ½æ ‡æ³¨: å®Œæˆ")
            print(f"âš™ï¸ ç‰¹å¾å·¥ç¨‹: ç”Ÿæˆ {final_report.get('data_statistics', {}).get('final_features', 0)} ä¸ªç‰¹å¾")
            print(f"ğŸ“„ æ–‡æœ¬æ‘˜è¦: ç”Ÿæˆ {final_report.get('data_statistics', {}).get('product_summaries', 0)} ä¸ªäº§å“æ‘˜è¦")
            print(f"ğŸ§  çŸ¥è¯†åº“: æ„å»ºå®Œæˆ")
            print(f"ğŸ’¬ é—®ç­”ç³»ç»Ÿ: å›ç­” {final_report.get('data_statistics', {}).get('qa_pairs', 0)} ä¸ªé—®é¢˜")
            print(f"ğŸ“ˆ æ•°æ®å®Œæ•´åº¦: {final_report.get('quality_metrics', {}).get('data_completeness', 0):.1f}%")
            print(f"â­ å¹³å‡è¯„åˆ†: {final_report.get('quality_metrics', {}).get('average_rating', 0):.2f}")
            print("="*60)
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.base_path}")
            print("="*60)

            return final_report

        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ MaestroDataflow ç»¼åˆAIå·¥ä½œæµæ¼”ç¤º")
    print("å±•ç¤ºå®Œæ•´çš„ç«¯åˆ°ç«¯AIæ•°æ®å¤„ç†èƒ½åŠ›")
    print("="*60)

    try:
        # åˆ›å»ºå¹¶è¿è¡Œå·¥ä½œæµ
        workflow = ComprehensiveAIWorkflow()
        result = workflow.run_complete_workflow()

        print("\nâœ… æ¼”ç¤ºæˆåŠŸå®Œæˆï¼")
        print("ğŸ” è¯·æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šå’Œæ•°æ®æ–‡ä»¶äº†è§£è¯¦ç»†ç»“æœã€‚")

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        logger.error(f"ä¸»å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    main()