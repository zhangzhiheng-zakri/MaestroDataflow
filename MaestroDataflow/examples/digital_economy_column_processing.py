#!/usr/bin/env python3
# -*- coding: utf-8 -*-
r"""
ä¸­å›½æ•°å­—ç»æµå‘å±•æ•°æ®åˆ—åå¤„ç†å·¥ä½œæµ
å¤„ç† D:\MaestroDataflow\sample_data\ä¸­å›½æ•°å­—ç»æµå‘å±•æ•°æ®ï¼ˆ2005-2023å¹´ï¼‰.xlsx æ–‡ä»¶çš„åˆ—å
"""

import os
import sys
import json
import pandas as pd
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from maestro.operators.data_column_process_ops import DataColumnProcessOperator
from maestro.operators.column_ops import ColumnMeaningGeneratorOperator
from maestro.serving.llm_serving import APILLMServing
from maestro.serving.enhanced_llm_serving import LocalLLMServing, EnhancedLLMServing


def create_real_llm_service():
    """åˆ›å»ºçœŸå®çš„LLMæœåŠ¡ï¼Œä¼˜å…ˆä½¿ç”¨DeepSeek API"""
    
    # é¦–å…ˆå°è¯•ä½¿ç”¨DeepSeek API
    try:
        print("ğŸš€ ä½¿ç”¨DeepSeek APIæœåŠ¡")
        api_serving = APILLMServing(
            api_url="https://api.deepseek.com/v1/chat/completions",
            api_key="sk-e987d89ccdbe46c6948112314096b038",
            model_name="deepseek-chat",
            max_tokens=1000,
            temperature=0.3,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ
            api_type="openai"  # DeepSeekå…¼å®¹OpenAI APIæ ¼å¼
        )
        
        # ä½¿ç”¨å¢å¼ºæœåŠ¡åŒ…è£…ï¼Œå¯ç”¨ç¼“å­˜
        llm_service = EnhancedLLMServing(
            base_serving=api_serving,
            enable_cache=True,
            cache_ttl=3600  # ç¼“å­˜1å°æ—¶
        )
        return llm_service, "deepseek_api"
    except Exception as e:
        print(f"âš ï¸ DeepSeek APIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # å¤‡é€‰ï¼šæ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„OpenAI APIå¯†é’¥
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key and api_key != "sk-123456":  # æ’é™¤æµ‹è¯•å¯†é’¥
            print("âœ… æ‰¾åˆ°OpenAI APIå¯†é’¥ï¼Œä½¿ç”¨APIæœåŠ¡")
            api_serving = APILLMServing(
                api_url="https://api.openai.com/v1/chat/completions",
                api_key=api_key,
                model_name="gpt-3.5-turbo",
                max_tokens=1000,
                temperature=0.3,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ
                api_type="openai"
            )
            
            # ä½¿ç”¨å¢å¼ºæœåŠ¡åŒ…è£…ï¼Œå¯ç”¨ç¼“å­˜
            llm_service = EnhancedLLMServing(
                base_serving=api_serving,
                enable_cache=True,
                cache_ttl=3600  # ç¼“å­˜1å°æ—¶
            )
            return llm_service, "openai_api"
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„OPENAI_API_KEYç¯å¢ƒå˜é‡")
    except Exception as e:
        print(f"âš ï¸ OpenAI APIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # å›é€€åˆ°æœ¬åœ°æ¨¡å‹
    try:
        print("ğŸ”„ å°è¯•ä½¿ç”¨æœ¬åœ°LLMæ¨¡å‹...")
        llm_service = LocalLLMServing(
            model_name="microsoft/DialoGPT-medium",
            device="cpu",
            max_tokens=500,
            temperature=0.3
        )
        return llm_service, "local_model"
    except Exception as e:
        print(f"âš ï¸ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›None
    print("âŒ æ— æ³•åˆå§‹åŒ–ä»»ä½•LLMæœåŠ¡ï¼Œå°†ä½¿ç”¨MockæœåŠ¡")
    return None, "mock"


class RealLLMColumnProcessor:
    """ä½¿ç”¨çœŸå®LLMçš„åˆ—åå¤„ç†å™¨"""
    
    def __init__(self, llm_service, service_type):
        self.llm_service = llm_service
        self.service_type = service_type
        
    def generate_column_meaning(self, column_name, sample_data=None):
        """ä½¿ç”¨çœŸå®LLMç”Ÿæˆåˆ—åå«ä¹‰"""
        if self.llm_service is None:
            return f"æ— æ³•åˆ†æåˆ—åï¼š{column_name}ï¼ˆLLMæœåŠ¡ä¸å¯ç”¨ï¼‰"
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰20å¹´ç ”ç©¶ç»éªŒçš„é¡¶å°–æ•°æ®åˆ†æä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£è§£é‡Šæ•°æ®ä¸­çš„åˆ—åå«ä¹‰å’Œå•ä½ï¼Œè‹¥åˆ—åä¸­æ— å•ä½ï¼Œç»“åˆæ„ä¹‰ç»™å‡ºå•ä½ã€‚

è¯·æ ¹æ®åˆ—åï¼Œæä¾›å‡†ç¡®ã€ä¸“ä¸šçš„è§£é‡Šã€‚è¦æ±‚ï¼š
1. æ„ä¹‰ï¼šè¯¦ç»†è¯´æ˜è¯¥å­—æ®µçš„å«ä¹‰ã€ç”¨é€”å’Œè®¡ç®—æ–¹æ³•
2. å•ä½ï¼šå‡†ç¡®æ ‡æ³¨æ•°æ®æˆ–æ„ä¹‰ä¸­çš„è®¡é‡å•ä½ï¼ˆå¦‚ï¼šå…ƒã€ä¸‡å…ƒã€%ã€ä¸ªç­‰ï¼‰

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
    "æ„ä¹‰": "è¯¦ç»†è§£é‡Š...",
    "å•ä½": "å•ä½åç§°"
}}

æ³¨æ„ï¼š
- å¦‚æœæ˜¯ç™¾åˆ†æ¯”æ•°æ®ï¼Œå•ä½å†™"%"
- å¦‚æœæ˜¯å¹´ä»½æ•°æ®ï¼Œå•ä½å†™"å¹´"
- å¦‚æœæ˜¯åˆ†æ•°æ•°æ®ï¼Œå•ä½å†™"åˆ†"
- å¦‚æœæ˜¯é‡‘é¢æ•°æ®ï¼Œé€šå¸¸å•ä½ä¸º"å…ƒ"æˆ–"ä¸‡å…ƒ"
- å¦‚æœæ˜¯æ•°é‡æ•°æ®ï¼Œå•ä½ä¸º"ä¸ª"ã€"åª"ã€"è‚¡"ç­‰
- å¦‚æœæ˜¯æ¯”ç‡æ•°æ®ï¼Œå¦‚å¢é•¿ç‡ã€å›æŠ¥ç‡ï¼Œå•ä½å†™"%"ï¼Œå¦‚æœæ˜¯å€ç‡ï¼Œå•ä½å†™"å€"ï¼Œè‹¥æ²¡æœ‰å•ä½ï¼Œå†™"æ²¡æœ‰å•ä½"
- è§£é‡Šè¦ä¸“ä¸šã€å‡†ç¡®ã€å®Œæ•´

éœ€è¦è§£é‡Šçš„åˆ—åï¼š
- {column_name}

ç¤ºä¾‹æ•°æ®ï¼š{sample_data if sample_data else "æ— "}

è¯·ç›´æ¥è¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—è¯´æ˜ã€‚"""
        
        try:
            response = self.llm_service.generate(prompt)
            return response.strip()
        except Exception as e:
            print(f"âš ï¸ LLMç”Ÿæˆå¤±è´¥: {e}")
            return f"åˆ—ååˆ†æå¤±è´¥ï¼š{column_name}"
    
    def standardize_column_name(self, column_name):
        """ä½¿ç”¨çœŸå®LLMæ ‡å‡†åŒ–åˆ—å"""
        if self.llm_service is None:
            # å›é€€åˆ°ç®€å•è§„åˆ™
            return column_name.lower().replace(' ', '_').replace('(', '').replace(')', '').replace('%', 'pct')
        
        prompt = f"""
è¯·å°†ä»¥ä¸‹ä¸­æ–‡åˆ—åè½¬æ¢ä¸ºæ ‡å‡†çš„è‹±æ–‡åˆ—åï¼š

åŸåˆ—åï¼š{column_name}

è¦æ±‚ï¼š
1. ä½¿ç”¨è‹±æ–‡å•è¯
2. ç”¨ä¸‹åˆ’çº¿è¿æ¥
3. å…¨éƒ¨å°å†™
4. ç®€æ´æ˜ç¡®
5. ç¬¦åˆæ•°æ®åº“å‘½åè§„èŒƒ

åªè¿”å›æ ‡å‡†åŒ–åçš„åˆ—åï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
"""
        
        try:
            response = self.llm_service.generate(prompt)
            # æ¸…ç†å“åº”ï¼Œåªä¿ç•™åˆ—å
            standardized = response.strip().lower()
            # ç§»é™¤å¯èƒ½çš„æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼
            standardized = ''.join(c if c.isalnum() or c == '_' else '_' for c in standardized)
            # ç§»é™¤è¿ç»­çš„ä¸‹åˆ’çº¿
            while '__' in standardized:
                standardized = standardized.replace('__', '_')
            return standardized.strip('_')
        except Exception as e:
            print(f"âš ï¸ LLMæ ‡å‡†åŒ–å¤±è´¥: {e}")
            return column_name.lower().replace(' ', '_')
    
    def generate_column_template(self, columns):
        """ä½¿ç”¨çœŸå®LLMç”Ÿæˆåˆ—åæ¨¡æ¿"""
        template = {}
        
        for col in columns:
            if col.strip() == '' or 'Unnamed' in col:
                continue
                
            # è·å–åˆ—çš„å«ä¹‰å’Œæ ‡å‡†å
            meaning = self.generate_column_meaning(col)
            standard_name = self.standardize_column_name(col)
            
            # æ¨æ–­æ•°æ®ç±»å‹
            data_type = self._infer_data_type(col)
            category = self._infer_category(col)
            
            template[col] = {
                'english_name': standard_name,
                'standard_name': standard_name,
                'meaning': meaning,
                'data_type': data_type,
                'category': category
            }
        
        return template
    
    def _infer_data_type(self, column_name):
        """æ¨æ–­æ•°æ®ç±»å‹"""
        if 'å¹´' in column_name or 'æŒ‡æ ‡' in column_name:
            return 'integer'
        elif '%' in column_name or 'ç‡' in column_name or 'æ¯”é‡' in column_name:
            return 'float'
        elif 'è§„æ¨¡' in column_name or 'ä¸‡äº¿' in column_name:
            return 'float'
        else:
            return 'string'
    
    def _infer_category(self, column_name):
        """æ¨æ–­åˆ—åˆ†ç±»"""
        if 'å¹´' in column_name or 'æŒ‡æ ‡' in column_name:
            return 'time_dimension'
        elif 'è§„æ¨¡' in column_name:
            return 'economic_scale'
        elif 'å¢é•¿' in column_name:
            return 'growth_rate'
        elif 'æ¯”é‡' in column_name:
            return 'economic_ratio'
        elif 'æ¸—é€ç‡' in column_name:
            return 'penetration_rate'
        else:
            return 'other'
class MockLLMService:
    """æ¨¡æ‹ŸLLMæœåŠ¡ï¼Œä¸ºä¸­å›½æ•°å­—ç»æµæ•°æ®æä¾›é¢„å®šä¹‰çš„åˆ—åæ˜ å°„ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    
    def __init__(self):
        # é¢„å®šä¹‰çš„ä¸­å›½æ•°å­—ç»æµæ•°æ®åˆ—åæ˜ å°„
        self.column_mappings = {
            'æŒ‡æ ‡': {
                'english_name': 'year_indicator',
                'standard_name': 'year',
                'meaning': 'å¹´ä»½æŒ‡æ ‡ï¼Œè¡¨ç¤ºæ•°æ®å¯¹åº”çš„å¹´ä»½',
                'data_type': 'integer',
                'category': 'time_dimension'
            },
            'æ•°å­—ç»æµè§„æ¨¡(ä¸‡äº¿å…ƒï¼‰': {
                'english_name': 'digital_economy_scale_trillion_yuan',
                'standard_name': 'digital_economy_scale',
                'meaning': 'æ•°å­—ç»æµæ€»è§„æ¨¡ï¼Œå•ä½ä¸ºä¸‡äº¿å…ƒäººæ°‘å¸',
                'data_type': 'float',
                'category': 'economic_scale'
            },
            'æ•°å­—ç»æµè§„æ¨¡åŒæ¯”åä¹‰å¢é•¿(%)': {
                'english_name': 'digital_economy_growth_rate_pct',
                'standard_name': 'digital_economy_growth_rate',
                'meaning': 'æ•°å­—ç»æµè§„æ¨¡åŒæ¯”åä¹‰å¢é•¿ç‡ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'growth_rate'
            },
            'æ•°å­—ç»æµè§„æ¨¡å GDPæ¯”é‡(%)': {
                'english_name': 'digital_economy_gdp_ratio_pct',
                'standard_name': 'digital_economy_gdp_ratio',
                'meaning': 'æ•°å­—ç»æµè§„æ¨¡å å›½å†…ç”Ÿäº§æ€»å€¼(GDP)çš„æ¯”é‡ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'economic_ratio'
            },
            'æ•°å­—äº§ä¸šåŒ–è§„æ¨¡(ä¸‡äº¿å…ƒ)': {
                'english_name': 'digital_industrialization_scale_trillion_yuan',
                'standard_name': 'digital_industrialization_scale',
                'meaning': 'æ•°å­—äº§ä¸šåŒ–è§„æ¨¡ï¼Œå³æ•°å­—æŠ€æœ¯äº§ä¸šæœ¬èº«çš„è§„æ¨¡ï¼Œå•ä½ä¸ºä¸‡äº¿å…ƒ',
                'data_type': 'float',
                'category': 'economic_scale'
            },
            'æ•°å­—äº§ä¸šåŒ–è§„æ¨¡åŒæ¯”åä¹‰å¢é•¿(%)': {
                'english_name': 'digital_industrialization_growth_rate_pct',
                'standard_name': 'digital_industrialization_growth_rate',
                'meaning': 'æ•°å­—äº§ä¸šåŒ–è§„æ¨¡åŒæ¯”åä¹‰å¢é•¿ç‡ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'growth_rate'
            },
            'æ•°å­—äº§ä¸šåŒ–è§„æ¨¡å æ•°å­—ç»æµæ¯”é‡(%)': {
                'english_name': 'digital_industrialization_digital_economy_ratio_pct',
                'standard_name': 'digital_industrialization_ratio',
                'meaning': 'æ•°å­—äº§ä¸šåŒ–è§„æ¨¡å æ•°å­—ç»æµæ€»è§„æ¨¡çš„æ¯”é‡ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'economic_ratio'
            },
            'æ•°å­—äº§ä¸šåŒ–è§„æ¨¡å GDPæ¯”é‡(%)': {
                'english_name': 'digital_industrialization_gdp_ratio_pct',
                'standard_name': 'digital_industrialization_gdp_ratio',
                'meaning': 'æ•°å­—äº§ä¸šåŒ–è§„æ¨¡å å›½å†…ç”Ÿäº§æ€»å€¼(GDP)çš„æ¯”é‡ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'economic_ratio'
            },
            'äº§ä¸šæ•°å­—åŒ–è§„æ¨¡(ä¸‡äº¿å…ƒ)': {
                'english_name': 'industry_digitalization_scale_trillion_yuan',
                'standard_name': 'industry_digitalization_scale',
                'meaning': 'äº§ä¸šæ•°å­—åŒ–è§„æ¨¡ï¼Œå³ä¼ ç»Ÿäº§ä¸šé€šè¿‡æ•°å­—åŒ–è½¬å‹äº§ç”Ÿçš„ç»æµä»·å€¼ï¼Œå•ä½ä¸ºä¸‡äº¿å…ƒ',
                'data_type': 'float',
                'category': 'economic_scale'
            },
            'äº§ä¸šæ•°å­—åŒ–è§„æ¨¡åŒæ¯”åä¹‰å¢é•¿(%)': {
                'english_name': 'industry_digitalization_growth_rate_pct',
                'standard_name': 'industry_digitalization_growth_rate',
                'meaning': 'äº§ä¸šæ•°å­—åŒ–è§„æ¨¡åŒæ¯”åä¹‰å¢é•¿ç‡ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'growth_rate'
            },
            'äº§ä¸šæ•°å­—åŒ–è§„æ¨¡å æ•°å­—ç»æµæ¯”é‡(%)': {
                'english_name': 'industry_digitalization_digital_economy_ratio_pct',
                'standard_name': 'industry_digitalization_ratio',
                'meaning': 'äº§ä¸šæ•°å­—åŒ–è§„æ¨¡å æ•°å­—ç»æµæ€»è§„æ¨¡çš„æ¯”é‡ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'economic_ratio'
            },
            'äº§ä¸šæ•°å­—åŒ–è§„æ¨¡å GDPæ¯”é‡(%)': {
                'english_name': 'industry_digitalization_gdp_ratio_pct',
                'standard_name': 'industry_digitalization_gdp_ratio',
                'meaning': 'äº§ä¸šæ•°å­—åŒ–è§„æ¨¡å å›½å†…ç”Ÿäº§æ€»å€¼(GDP)çš„æ¯”é‡ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'economic_ratio'
            },
            'å†œä¸šæ•°å­—ç»æµæ¸—é€ç‡(%)': {
                'english_name': 'agriculture_digital_penetration_rate_pct',
                'standard_name': 'agriculture_digital_penetration',
                'meaning': 'å†œä¸šé¢†åŸŸæ•°å­—ç»æµæ¸—é€ç‡ï¼Œåæ˜ æ•°å­—æŠ€æœ¯åœ¨å†œä¸šä¸­çš„åº”ç”¨ç¨‹åº¦ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'penetration_rate'
            },
            'å·¥ä¸šæ•°å­—ç»æµæ¸—é€ç‡(%)': {
                'english_name': 'industry_digital_penetration_rate_pct',
                'standard_name': 'industry_digital_penetration',
                'meaning': 'å·¥ä¸šé¢†åŸŸæ•°å­—ç»æµæ¸—é€ç‡ï¼Œåæ˜ æ•°å­—æŠ€æœ¯åœ¨å·¥ä¸šä¸­çš„åº”ç”¨ç¨‹åº¦ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'penetration_rate'
            },
            'æœåŠ¡ä¸šæ•°å­—ç»æµæ¸—é€ç‡(%)': {
                'english_name': 'service_digital_penetration_rate_pct',
                'standard_name': 'service_digital_penetration',
                'meaning': 'æœåŠ¡ä¸šé¢†åŸŸæ•°å­—ç»æµæ¸—é€ç‡ï¼Œåæ˜ æ•°å­—æŠ€æœ¯åœ¨æœåŠ¡ä¸šä¸­çš„åº”ç”¨ç¨‹åº¦ï¼Œä»¥ç™¾åˆ†æ¯”è¡¨ç¤º',
                'data_type': 'float',
                'category': 'penetration_rate'
            },
            'Unnamed: 15': {
                'english_name': 'empty_column',
                'standard_name': 'unused_column',
                'meaning': 'ç©ºåˆ—ï¼Œæ— å®é™…æ•°æ®å†…å®¹ï¼Œå»ºè®®åˆ é™¤',
                'data_type': 'null',
                'category': 'unused'
            }
        }
    
    def generate_column_meaning(self, column_name, sample_data=None):
        """ç”Ÿæˆåˆ—åå«ä¹‰"""
        if column_name in self.column_mappings:
            return self.column_mappings[column_name]['meaning']
        return f"æœªçŸ¥åˆ—åï¼š{column_name}ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ"
    
    def standardize_column_name(self, column_name):
        """æ ‡å‡†åŒ–åˆ—å"""
        if column_name in self.column_mappings:
            return self.column_mappings[column_name]['standard_name']
        return column_name.lower().replace(' ', '_').replace('(', '').replace(')', '').replace('%', 'pct')
    
    def generate_column_template(self, columns):
        """ç”Ÿæˆåˆ—åæ¨¡æ¿"""
        template = {}
        for col in columns:
            if col in self.column_mappings:
                template[col] = self.column_mappings[col]
            else:
                template[col] = {
                    'english_name': col.lower().replace(' ', '_'),
                    'standard_name': col.lower().replace(' ', '_'),
                    'meaning': f"éœ€è¦åˆ†æçš„åˆ—ï¼š{col}",
                    'data_type': 'unknown',
                    'category': 'unknown'
                }
        return template


def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œä¸­å›½æ•°å­—ç»æµæ•°æ®åˆ—åå¤„ç†å·¥ä½œæµ"""
    
    # è®¾ç½®è¾“å‡ºç›®å½• - ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„output
    output_dir = project_root / "output" / "digital_economy_column_processing"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„
    data_file = project_root / "sample_data" / "ä¸­å›½æ•°å­—ç»æµå‘å±•æ•°æ®ï¼ˆ2005-2023å¹´ï¼‰.xlsx"
    
    print(f"å¼€å§‹å¤„ç†ä¸­å›½æ•°å­—ç»æµå‘å±•æ•°æ®åˆ—å...")
    print(f"æ•°æ®æ–‡ä»¶: {data_file}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    try:
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(data_file)
        print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"åˆ—å: {df.columns.tolist()}")
        
        # ä¿å­˜ä¸ºCSVæ ¼å¼ä»¥ä¾¿åç»­å¤„ç†
        csv_file = output_dir / "digital_economy_data.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"å·²ä¿å­˜CSVæ–‡ä»¶: {csv_file}")
        
        # å¤„ç†åˆ—åï¼ˆå»é™¤ç©ºåˆ—ï¼‰
        valid_columns = [col for col in df.columns if not col.startswith('Unnamed')]
        print(f"æœ‰æ•ˆåˆ—å: {valid_columns}")
        
        # åˆå§‹åŒ–LLMæœåŠ¡ï¼ˆä¼˜å…ˆä½¿ç”¨çœŸå®LLMï¼‰
        print("\n=== åˆå§‹åŒ–LLMæœåŠ¡ ===")
        llm_service, service_type = create_real_llm_service()
        
        if service_type == "mock":
            # ä½¿ç”¨MockæœåŠ¡ä½œä¸ºå¤‡ç”¨
            print("ğŸ”„ ä½¿ç”¨Mock LLMæœåŠ¡ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
            mock_service = MockLLMService()
            processor = RealLLMColumnProcessor(None, "mock")
            # ä½¿ç”¨MockæœåŠ¡çš„æ–¹æ³•
            column_meanings = {}
            column_template = mock_service.generate_column_template(valid_columns)
            column_name_mapping = {col: mock_service.standardize_column_name(col) for col in valid_columns}
        else:
            # ä½¿ç”¨çœŸå®LLMæœåŠ¡
            print(f"âœ… ä½¿ç”¨çœŸå®LLMæœåŠ¡: {service_type}")
            processor = RealLLMColumnProcessor(llm_service, service_type)
            
            # ç”Ÿæˆåˆ—åå«ä¹‰
            print("ğŸ“ ç”Ÿæˆåˆ—åå«ä¹‰...")
            column_meanings = {}
            for col in valid_columns:
                print(f"  å¤„ç†åˆ—: {col}")
                meaning = processor.generate_column_meaning(col, df[col].head(3).tolist() if col in df.columns else None)
                column_meanings[col] = meaning
            
            # ç”Ÿæˆåˆ—åæ¨¡æ¿
            print("ğŸ“‹ ç”Ÿæˆåˆ—åæ¨¡æ¿...")
            column_template = processor.generate_column_template(valid_columns)
            
            # ç”Ÿæˆåˆ—åæ˜ å°„
            print("ğŸ”„ ç”Ÿæˆæ ‡å‡†åŒ–åˆ—åæ˜ å°„...")
            column_name_mapping = {}
            for col in valid_columns:
                standard_name = processor.standardize_column_name(col)
                column_name_mapping[col] = standard_name
        
        # ä¿å­˜å¤„ç†ç»“æœ
        print("\n=== ä¿å­˜å¤„ç†ç»“æœ ===")
        
        # ä¿å­˜åˆ—åå«ä¹‰
        meanings_file = output_dir / "column_meanings.json"
        with open(meanings_file, 'w', encoding='utf-8') as f:
            json.dump(column_meanings, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²ä¿å­˜åˆ—åå«ä¹‰: {meanings_file}")
        
        # ä¿å­˜åˆ—åæ¨¡æ¿
        template_file = output_dir / "column_template.json"
        with open(template_file, 'w', encoding='utf-8') as f:
            json.dump(column_template, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²ä¿å­˜åˆ—åæ¨¡æ¿: {template_file}")
        
        # ä¿å­˜åˆ—åæ˜ å°„
        mapping_file = output_dir / "column_name_mapping.json"
        with open(mapping_file, 'w', encoding='utf-8') as f:
            json.dump(column_name_mapping, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²ä¿å­˜åˆ—åæ˜ å°„: {mapping_file}")
        
        # åˆ›å»ºæ ‡å‡†åŒ–æ•°æ®
        print("ğŸ”„ åˆ›å»ºæ ‡å‡†åŒ–æ•°æ®...")
        df_standardized = df.copy()
        df_standardized = df_standardized.rename(columns=column_name_mapping)
        
        # ä¿å­˜æ ‡å‡†åŒ–æ•°æ®
        standardized_file = output_dir / "digital_economy_data_standardized.csv"
        df_standardized.to_csv(standardized_file, index=False, encoding='utf-8-sig')
        print(f"âœ… å·²ä¿å­˜æ ‡å‡†åŒ–æ•°æ®: {standardized_file}")
        
        # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
        report = {
            "processing_info": {
                "data_file": str(data_file),
                "processing_time": datetime.now().isoformat(),
                "llm_service_type": service_type,
                "data_shape": {
                    "rows": df.shape[0],
                    "columns": df.shape[1],
                    "valid_columns": len(valid_columns)
                }
            },
            "column_info": {
                "original_columns": df.columns.tolist(),
                "valid_columns": valid_columns,
                "standardized_columns": list(column_name_mapping.values())[:5]  # åªæ˜¾ç¤ºå‰5ä¸ª
            }
        }
        
        report_file = output_dir / "processing_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²ä¿å­˜å¤„ç†æŠ¥å‘Š: {report_file}")
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼ä½¿ç”¨çš„LLMæœåŠ¡ç±»å‹: {service_type}")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        
        return True
        
    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    if success:
        print("ä¸­å›½æ•°å­—ç»æµæ•°æ®åˆ—åå¤„ç†å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
    else:
        print("ä¸­å›½æ•°å­—ç»æµæ•°æ®åˆ—åå¤„ç†å·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼")
        sys.exit(1)