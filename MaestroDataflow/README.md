# MaestroDataflow

MaestroDataflow æ˜¯ä¸€ä¸ªå¼ºå¤§çš„AIå¢å¼ºæ•°æ®å¤„ç†æ¡†æ¶ï¼Œä¸“ä¸ºé«˜æ•ˆå¤„ç†å¤šç§æ ¼å¼çš„æ•°æ®æ–‡ä»¶è€Œè®¾è®¡ã€‚å®ƒä¸ä»…æä¾›äº†ç»Ÿä¸€çš„æ¥å£æ¥å¤„ç† XLSXã€CSVã€JSONã€JSONL å’Œ Parquet æ ¼å¼çš„æ•°æ®ï¼Œè¿˜é›†æˆäº†å…ˆè¿›çš„AIåŠŸèƒ½ï¼ŒåŒ…æ‹¬å‘é‡æ•°æ®åº“ã€æ¨¡å‹ç¼“å­˜å’Œæ™ºèƒ½æ•°æ®å¤„ç†æ“ä½œç¬¦ã€‚

## ç‰¹ç‚¹

### æ ¸å¿ƒåŠŸèƒ½
- **å¤šæ ¼å¼æ”¯æŒ**ï¼šæ— ç¼å¤„ç† XLSXã€CSVã€JSONã€JSONL å’Œ Parquet æ ¼å¼çš„æ•°æ®æ–‡ä»¶
- **ç»Ÿä¸€æ¥å£**ï¼šä½¿ç”¨ä¸€è‡´çš„ API å¤„ç†ä¸åŒæ ¼å¼çš„æ•°æ®
- **ç®€å•æ˜“ç”¨**ï¼šç›´è§‚çš„æ–¹æ³•å‘½åå’Œé“¾å¼è°ƒç”¨æ”¯æŒ
- **é«˜æ•ˆå¤„ç†**ï¼šä¼˜åŒ–çš„æ•°æ®å¤„ç†æµç¨‹ï¼Œæ”¯æŒå¤§å‹æ•°æ®é›†
- **æ ¼å¼è½¬æ¢**ï¼šè½»æ¾åœ¨ä¸åŒæ ¼å¼ä¹‹é—´è½¬æ¢æ•°æ®
- **ç¼“å­˜æœºåˆ¶**ï¼šå†…ç½®ç¼“å­˜ç³»ç»Ÿï¼Œæé«˜å¤„ç†æ•ˆç‡
- **ç®¡é“å¤„ç†**ï¼šæ”¯æŒå¤æ‚çš„æ•°æ®å¤„ç†ç®¡é“å’Œæ“ä½œç¬¦

### AIå¢å¼ºåŠŸèƒ½
- **å‘é‡æ•°æ®åº“**ï¼šå†…ç½®å‘é‡å­˜å‚¨å’Œç›¸ä¼¼æ€§æœç´¢åŠŸèƒ½
- **æ¨¡å‹ç¼“å­˜**ï¼šæ™ºèƒ½æ¨¡å‹è¾“å‡ºç¼“å­˜ï¼Œæé«˜AIåº”ç”¨æ€§èƒ½
- **AIæ“ä½œç¬¦**ï¼šä¸°å¯Œçš„AIæ•°æ®å¤„ç†æ“ä½œç¬¦ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†æã€æƒ…æ„Ÿåˆ†æç­‰
- **LLMé›†æˆ**ï¼šæ”¯æŒæœ¬åœ°å’ŒAPI LLMæœåŠ¡é›†æˆ
- **æ™ºèƒ½æ•°æ®æ¸…æ´—**ï¼šåŸºäºAIçš„è‡ªåŠ¨æ•°æ®æ¸…æ´—å’Œè´¨é‡æ£€æµ‹

### æ•°æ®åˆ†æä¸å¯è§†åŒ–åŠŸèƒ½ ğŸ†•
- **ç»Ÿè®¡åˆ†æ**ï¼šå…¨é¢çš„æè¿°æ€§ç»Ÿè®¡ã€å¢é•¿ç‡è®¡ç®—ã€è¶‹åŠ¿åˆ†æ
- **æ•°æ®å¯è§†åŒ–**ï¼šæ”¯æŒçº¿å›¾ã€æŸ±çŠ¶å›¾ã€æ•£ç‚¹å›¾ã€é¥¼å›¾ã€çƒ­åŠ›å›¾ç­‰å¤šç§å›¾è¡¨ç±»å‹
- **äº¤äº’å¼ä»ªè¡¨æ¿**ï¼šåŸºäºPlotlyçš„å“åº”å¼ä»ªè¡¨æ¿ç”Ÿæˆ
- **ä¸“ä¸šæŠ¥å‘Š**ï¼šè‡ªåŠ¨ç”ŸæˆHTML/PDFæ ¼å¼çš„æ•°æ®åˆ†ææŠ¥å‘Š
- **æ¨¡æ¿ç³»ç»Ÿ**ï¼šæä¾›å¤šç§æŠ¥å‘Šæ¨¡æ¿ï¼ˆç»¼åˆæŠ¥å‘Šã€æ‰§è¡Œæ‘˜è¦ã€æŠ€æœ¯æŠ¥å‘Šï¼‰

## å®‰è£…

```bash
pip install MaestroDataflow
```

æˆ–è€…ä»æºä»£ç å®‰è£…ï¼š

```bash
git clone https://github.com/maestro-dataflow/MaestroDataflow.git
cd MaestroDataflow
pip install -e .
```

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ç”¨æ³•

```python
from maestro.utils.storage import FileStorage
from maestro.pipeline.pipeline import Pipeline
from maestro.operators.basic_ops import FilterRowsOperator, SelectColumnsOperator

# åˆ›å»ºå­˜å‚¨å®ä¾‹
storage = FileStorage(
    input_file_path="../sample_data/employees.csv",
    cache_path="../output/basic_example/cache",
    file_name_prefix="process",
    cache_type="xlsx"
)

# åˆ›å»ºç®¡é“å’Œæ“ä½œç¬¦
pipeline = Pipeline(storage=storage)
filter_op = FilterRowsOperator(condition=lambda row: row['salary'] > 50000)
select_op = SelectColumnsOperator(columns=['name', 'department', 'salary'])

# æ·»åŠ æ“ä½œç¬¦åˆ°ç®¡é“
pipeline.add_operator(filter_op)
pipeline.add_operator(select_op)

# è¿è¡Œç®¡é“
pipeline.run()

# è¯»å–å¤„ç†ç»“æœ
result_data = storage.step().read()
print(result_data)
```

### æ•°æ®åˆ†æä¸å¯è§†åŒ–ç¤ºä¾‹ ğŸ†•

```python
from maestro.pipeline.pipeline import Pipeline
from maestro.utils.storage import FileStorage
from maestro.operators.analytics_ops import DataAnalysisOperator, DataSummaryOperator
from maestro.operators.visualization_ops import ChartGeneratorOperator, DashboardGeneratorOperator
from maestro.operators.report_ops import HTMLReportGeneratorOperator

# åˆ›å»ºå­˜å‚¨å®ä¾‹
storage = FileStorage(
    input_file_path="../data/sales_data.csv",
    cache_path="../output/analytics_example/cache"
)

# åˆ›å»ºæ•°æ®åˆ†æå·¥ä½œæµ
workflow = Pipeline(storage=storage)

# æ·»åŠ æ•°æ®åˆ†æç®—å­
analysis_op = DataAnalysisOperator(
    columns_to_analyze=['é”€å”®é¢', 'åˆ©æ¶¦ç‡'],
    time_column='æ—¥æœŸ',
    include_growth_analysis=True
)

# æ·»åŠ å›¾è¡¨ç”Ÿæˆç®—å­
chart_op = ChartGeneratorOperator(
    chart_type='line',
    x_column='æ—¥æœŸ',
    y_columns=['é”€å”®é¢'],
    title='é”€å”®è¶‹åŠ¿åˆ†æ',
    output_file='sales_trend.png'
)

# æ·»åŠ ä»ªè¡¨æ¿ç”Ÿæˆç®—å­
dashboard_op = DashboardGeneratorOperator(
    dashboard_title='é”€å”®æ•°æ®ä»ªè¡¨æ¿',
    chart_configs=[
        {
            'type': 'line',
            'x_column': 'æ—¥æœŸ',
            'y_columns': ['é”€å”®é¢'],
            'title': 'é”€å”®è¶‹åŠ¿'
        },
        {
            'type': 'bar',
            'x_column': 'æœˆä»½',
            'y_columns': ['åˆ©æ¶¦ç‡'],
            'title': 'æœˆåº¦åˆ©æ¶¦ç‡'
        }
    ]
)

# æ·»åŠ æŠ¥å‘Šç”Ÿæˆç®—å­
report_op = HTMLReportGeneratorOperator(
    report_title='é”€å”®æ•°æ®åˆ†ææŠ¥å‘Š',
    output_file='sales_report.html',
    template_style='modern'
)

# æ„å»ºå·¥ä½œæµ
workflow.add_operator("analysis", analysis_op)
workflow.add_operator("chart", chart_op, depends_on=["analysis"])
workflow.add_operator("dashboard", dashboard_op, depends_on=["chart"])
workflow.add_operator("report", report_op, depends_on=["dashboard"])

# æ‰§è¡Œå·¥ä½œæµ
result = workflow.run(sales_data)
```

### AIå¢å¼ºå­˜å‚¨ç³»ç»Ÿ

```python
from maestro.utils.storage import FileStorage

# åˆ›å»ºAIå¢å¼ºçš„FileStorageå®ä¾‹
storage = FileStorage(
    input_file_path="./sample_data/employees.csv",
    cache_path="./cache",
    file_name_prefix="ai_process",
    cache_type="csv",
    enable_vector_storage=True,    # å¯ç”¨å‘é‡å­˜å‚¨
    enable_model_cache=True,       # å¯ç”¨æ¨¡å‹ç¼“å­˜
    vector_db_config={"similarity_metric": "cosine"},
    model_cache_config={
        "cache_type": "hybrid",
        "cache_config": {
            "memory": {"max_size": 100, "default_ttl": 3600},
            "disk": {"cache_dir": "./cache/model_cache", "max_size_mb": 500}
        }
    }
)

# åˆå§‹åŒ–å¹¶è¯»å–æ•°æ®
storage.step()
data = storage.read("dataframe")

# ä½¿ç”¨AIåŠŸèƒ½
import numpy as np

# æ·»åŠ å‘é‡åˆ°å‘é‡æ•°æ®åº“
vectors = np.random.rand(10, 128)  # ç¤ºä¾‹å‘é‡
metadata = [{"id": i, "text": f"sample_{i}"} for i in range(10)]
storage.add_vectors(vectors, metadata)

# æœç´¢ç›¸ä¼¼å‘é‡
query_vector = np.random.rand(128)
results = storage.search_vectors(query_vector, top_k=5)
print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸ä¼¼ç»“æœ")
```

### æ•°æ®åˆ†æä¸å¯è§†åŒ–ç®—å­ ğŸ†•
- **DataAnalysisOperator**: å…¨é¢çš„ç»Ÿè®¡åˆ†æï¼ŒåŒ…æ‹¬æè¿°æ€§ç»Ÿè®¡ã€å¢é•¿ç‡è®¡ç®—
- **DataSummaryOperator**: æ•°æ®æ‘˜è¦å’Œè´¨é‡è¯„ä¼°ï¼Œæ”¯æŒç›¸å…³æ€§åˆ†æ
- **ChartGeneratorOperator**: å¤šç§å›¾è¡¨ç±»å‹ç”Ÿæˆï¼ˆçº¿å›¾ã€æŸ±çŠ¶å›¾ã€æ•£ç‚¹å›¾ã€é¥¼å›¾ã€çƒ­åŠ›å›¾ã€ç®±çº¿å›¾ï¼‰
- **DashboardGeneratorOperator**: äº¤äº’å¼ä»ªè¡¨æ¿ç”Ÿæˆï¼Œæ”¯æŒå¤šå›¾è¡¨ç»„åˆ
- **HTMLReportGeneratorOperator**: ä¸“ä¸šHTMLæŠ¥å‘Šç”Ÿæˆï¼Œæ”¯æŒå¤šç§æ¨¡æ¿æ ·å¼
- **PDFReportGeneratorOperator**: PDFæ ¼å¼æŠ¥å‘Šç”Ÿæˆ
- **ReportTemplateOperator**: é¢„å®šä¹‰æŠ¥å‘Šæ¨¡æ¿ï¼ˆç»¼åˆæŠ¥å‘Šã€æ‰§è¡Œæ‘˜è¦ã€æŠ€æœ¯æŠ¥å‘Šï¼‰

### AIæ“ä½œç¬¦ä½¿ç”¨

```python
from maestro.operators.ai_ops import TextAnalysisOperator, SentimentAnalysisOperator
from maestro.serving.llm_serving import APILLMServing

# åˆ›å»ºLLMæœåŠ¡
llm_serving = APILLMServing(
    api_key="your_api_key",
    model_name="gpt-3.5-turbo",
    base_url="https://api.openai.com/v1"
)

# åˆ›å»ºAIæ“ä½œç¬¦
text_analysis_op = TextAnalysisOperator(
    llm_serving=llm_serving,
    analysis_type="keyword_extraction",
    target_column="content"
)

sentiment_op = SentimentAnalysisOperator(
    llm_serving=llm_serving,
    target_column="content",
    output_column="sentiment"
)

# åœ¨ç®¡é“ä¸­ä½¿ç”¨AIæ“ä½œç¬¦
pipeline = Pipeline(storage=storage)
pipeline.add_operator(text_analysis_op)
pipeline.add_operator(sentiment_op)
pipeline.run()
```

### ç›´æ¥ä½¿ç”¨å­˜å‚¨ç³»ç»Ÿ

```python
from maestro.utils.storage import FileStorage

# åˆ›å»ºFileStorageå®ä¾‹
storage = FileStorage(
    input_file_path="path/to/your/data.xlsx",  # æ”¯æŒxlsxã€csvã€jsonã€jsonl
    cache_path="./cache",                       # ç¼“å­˜ç›®å½•
    file_name_prefix="example",                 # ç¼“å­˜æ–‡ä»¶åå‰ç¼€
    cache_type="xlsx"                           # è¾“å‡ºæ–‡ä»¶ç±»å‹
)

# åˆå§‹åŒ–å¹¶è¯»å–æ•°æ®
storage.step()
data = storage.read("dataframe")  # æˆ– "dict"

# å¤„ç†æ•°æ®
processed_data = data[data['score'] > 80]

# ä¿å­˜å¤„ç†ç»“æœ
result_path = storage.write(processed_data)
print(f"ç»“æœå·²ä¿å­˜è‡³: {result_path}")
```

### æ ¼å¼è½¬æ¢

```python
# ä»XLSXè¯»å–
storage_in = FileStorage(
    input_file_path="data.xlsx",
    cache_path="./cache",
    file_name_prefix="original",
    cache_type="xlsx"
)

# åˆå§‹åŒ–å¹¶è¯»å–æ•°æ®
storage_in.step()
data = storage_in.read("dataframe")

# è½¬æ¢ä¸ºJSONæ ¼å¼ä¿å­˜
storage_out = FileStorage(
    input_file_path="dummy.xlsx",  # ä¸ä¼šå®é™…ä½¿ç”¨æ­¤æ–‡ä»¶
    cache_path="./cache",
    file_name_prefix="converted",
    cache_type="json"
)

json_path = storage_out.write(data)
print(f"å·²è½¬æ¢ä¸ºJSON: {json_path}")
```

## æ”¯æŒçš„æ–‡ä»¶ç±»å‹

- **XLSX**: Excelæ–‡ä»¶æ ¼å¼
- **CSV**: é€—å·åˆ†éš”å€¼æ–‡ä»¶
- **JSON**: JavaScriptå¯¹è±¡è¡¨ç¤ºæ³•
- **JSONL**: æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
- **Parquet**: é«˜æ•ˆçš„åˆ—å¼å­˜å‚¨æ ¼å¼
- **Pickle**: Pythonå¯¹è±¡åºåˆ—åŒ–æ ¼å¼

## æ ¸å¿ƒåŠŸèƒ½

MaestroDataflow æä¾›äº†ä¸°å¯Œçš„æ•°æ®å¤„ç†åŠŸèƒ½ï¼š

### å­˜å‚¨ç³»ç»Ÿ
- **FileStorage**: æ–‡ä»¶å­˜å‚¨ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼Œé›†æˆAIåŠŸèƒ½
- **DBStorage**: æ•°æ®åº“å­˜å‚¨ç³»ç»Ÿï¼Œæ”¯æŒSQLiteç­‰æ•°æ®åº“
- **VectorStorage**: å‘é‡æ•°æ®åº“å­˜å‚¨ï¼Œæ”¯æŒç›¸ä¼¼æ€§æœç´¢

### åŸºç¡€æ“ä½œç¬¦
- **FilterRowsOperator**: æ ¹æ®æ¡ä»¶ç­›é€‰æ•°æ®è¡Œ
- **SelectColumnsOperator**: é€‰æ‹©ç‰¹å®šåˆ—
- **MapRowsOperator**: å¯¹æ•°æ®è¡Œåº”ç”¨è‡ªå®šä¹‰å‡½æ•°
- **AggregateOperator**: æ•°æ®èšåˆæ“ä½œ
- **SortOperator**: æ•°æ®æ’åºæ“ä½œ

### AIæ“ä½œç¬¦
- **TextAnalysisOperator**: æ–‡æœ¬åˆ†æå’Œå…³é”®è¯æå–
- **SentimentAnalysisOperator**: æƒ…æ„Ÿåˆ†æ
- **DataCleaningOperator**: æ™ºèƒ½æ•°æ®æ¸…æ´—
- **EmbeddingOperator**: æ–‡æœ¬å‘é‡åŒ–
- **SimilaritySearchOperator**: ç›¸ä¼¼æ€§æœç´¢

### LLMæœåŠ¡
- **APILLMServing**: APIæ–¹å¼è°ƒç”¨LLMæœåŠ¡ï¼ˆOpenAIã€Azureç­‰ï¼‰
- **LocalLLMServing**: æœ¬åœ°LLMæ¨¡å‹æœåŠ¡
- **EnhancedLLMServing**: å¢å¼ºçš„LLMæœåŠ¡ï¼Œæ”¯æŒç¼“å­˜å’Œé‡è¯•

### ç®¡é“ç³»ç»Ÿ
- **Pipeline**: æ•°æ®å¤„ç†ç®¡é“ï¼Œæ”¯æŒé“¾å¼æ“ä½œ
- **BatchPipeline**: æ‰¹å¤„ç†ç®¡é“ï¼Œæ”¯æŒå¤§æ•°æ®é›†å¤„ç†
- **æ­¥éª¤ç®¡ç†**: è‡ªåŠ¨ç®¡ç†å¤„ç†æ­¥éª¤å’Œç¼“å­˜
- **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶

## é¡¹ç›®ç»“æ„

```
MaestroDataflow/
â”œâ”€â”€ maestro/                    # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ core/                   # æ ¸å¿ƒç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ operator.py         # æ“ä½œç¬¦åŸºç±»
â”‚   â”‚   â”œâ”€â”€ processor.py        # æ•°æ®å¤„ç†å™¨
â”‚   â”‚   â””â”€â”€ prompt.py           # AIæç¤ºæ¨¡æ¿
â”‚   â”œâ”€â”€ operators/              # æ“ä½œç¬¦
â”‚   â”‚   â”œâ”€â”€ basic_ops.py        # åŸºç¡€æ“ä½œç¬¦
â”‚   â”‚   â”œâ”€â”€ io_ops.py           # è¾“å…¥è¾“å‡ºæ“ä½œç¬¦
â”‚   â”‚   â”œâ”€â”€ llm_ops.py          # LLMæ“ä½œç¬¦
â”‚   â”‚   â”œâ”€â”€ analytics_ops.py    # æ•°æ®åˆ†æç®—å­ ğŸ†•
â”‚   â”‚   â”œâ”€â”€ visualization_ops.py # æ•°æ®å¯è§†åŒ–ç®—å­ ğŸ†•
â”‚   â”‚   â”œâ”€â”€ report_ops.py       # æŠ¥å‘Šç”Ÿæˆç®—å­ ğŸ†•
â”‚   â”‚   â””â”€â”€ ai_ops/             # AIæ“ä½œç¬¦ç›®å½•
â”‚   â”‚       â”œâ”€â”€ text_analysis.py      # æ–‡æœ¬åˆ†æ
â”‚   â”‚       â”œâ”€â”€ sentiment_analysis.py # æƒ…æ„Ÿåˆ†æ
â”‚   â”‚       â”œâ”€â”€ data_cleaning.py      # æ•°æ®æ¸…æ´—
â”‚   â”‚       â””â”€â”€ intelligent_processing.py # æ™ºèƒ½å¤„ç†
â”‚   â”œâ”€â”€ pipeline/               # ç®¡é“ç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ pipeline.py         # ç®¡é“å®ç°
â”‚   â”‚   â””â”€â”€ nodes.py            # ç®¡é“èŠ‚ç‚¹
â”‚   â”œâ”€â”€ utils/                  # å·¥å…·ç±»
â”‚   â”‚   â”œâ”€â”€ storage.py          # æ–‡ä»¶å­˜å‚¨
â”‚   â”‚   â”œâ”€â”€ db_storage.py       # æ•°æ®åº“å­˜å‚¨
â”‚   â”‚   â”œâ”€â”€ vector_db.py        # å‘é‡æ•°æ®åº“
â”‚   â”‚   â””â”€â”€ model_cache.py      # æ¨¡å‹ç¼“å­˜
â”‚   â””â”€â”€ serving/                # æœåŠ¡ç»„ä»¶
â”‚       â”œâ”€â”€ llm_serving.py      # LLMæœåŠ¡
â”‚       â””â”€â”€ enhanced_llm_serving.py # å¢å¼ºLLMæœåŠ¡
â”œâ”€â”€ test/                       # æµ‹è¯•æ–‡ä»¶
â”‚   â”œâ”€â”€ test_basic.py           # åŸºç¡€åŠŸèƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_storage.py         # å­˜å‚¨æµ‹è¯•
â”‚   â”œâ”€â”€ test_db_storage.py      # æ•°æ®åº“å­˜å‚¨æµ‹è¯•
â”‚   â”œâ”€â”€ test_integration.py     # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ db/                     # æµ‹è¯•æ•°æ®åº“
â”œâ”€â”€ examples/                   # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ advanced_pipeline_example.py    # é«˜çº§ç®¡é“ç¤ºä¾‹
â”‚   â”œâ”€â”€ ai_operators_demo.py            # AIæ“ä½œç¬¦æ¼”ç¤º
â”‚   â”œâ”€â”€ comprehensive_ai_workflow.py    # ç»¼åˆAIå·¥ä½œæµ
â”‚   â”œâ”€â”€ digital_economy_analysis.py     # æ•°å­—ç»æµæ•°æ®åˆ†æç¤ºä¾‹ ğŸ†•
â”‚   â””â”€â”€ README_ANALYTICS.md             # æ•°æ®åˆ†æåŠŸèƒ½æ–‡æ¡£ ğŸ†•
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”‚   â”œâ”€â”€ API_REFERENCE.md        # APIå‚è€ƒ
â”‚   â””â”€â”€ AI_OPERATORS_GUIDE.md   # AIæ“ä½œç¬¦æŒ‡å—
â”œâ”€â”€ sample_data/                # ç¤ºä¾‹æ•°æ®
â””â”€â”€ output/                     # è¾“å‡ºç›®å½• ğŸ†•
    â”œâ”€â”€ advanced_pipeline_example/      # é«˜çº§ç®¡é“ç¤ºä¾‹è¾“å‡º
    â”œâ”€â”€ ai_operators_demo/              # AIæ“ä½œç¬¦æ¼”ç¤ºè¾“å‡º
    â”œâ”€â”€ comprehensive_ai_workflow/      # ç»¼åˆå·¥ä½œæµè¾“å‡º
    â””â”€â”€ digital_economy_analysis/       # æ•°å­—ç»æµåˆ†æè¾“å‡º
```

## ç¤ºä¾‹

æŸ¥çœ‹ `examples/` ç›®å½•è·å–å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹ï¼ŒåŒ…æ‹¬ï¼š

- **advanced_pipeline_example.py**: é«˜çº§ç®¡é“å¤„ç†ç¤ºä¾‹ï¼Œå±•ç¤ºPipelineæ¡†æ¶ã€æ•°æ®åº“å­˜å‚¨å’ŒAIæ¨¡å‹æœåŠ¡çš„é›†æˆä½¿ç”¨
- **ai_operators_demo.py**: AIæ“ä½œç¬¦åŠŸèƒ½æ¼”ç¤ºï¼Œå±•ç¤ºå„ç§AIæ“ä½œç¬¦çš„ä½¿ç”¨æ–¹æ³•å’ŒåŠŸèƒ½
- **comprehensive_ai_workflow.py**: å®Œæ•´çš„AIæ•°æ®å¤„ç†å·¥ä½œæµï¼Œå±•ç¤ºå¤æ‚çš„AIæ•°æ®å¤„ç†åœºæ™¯
- **digital_economy_analysis.py**: æ•°å­—ç»æµæ•°æ®åˆ†æå®Œæ•´ç¤ºä¾‹ï¼Œæ¼”ç¤ºæ•°æ®åˆ†æã€å¯è§†åŒ–å’ŒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½ 
- **integrated_column_processing_workflow.py**: æ•´åˆçš„ä¸‰æ­¥éª¤åˆ—å¤„ç†å·¥ä½œæµï¼Œå±•ç¤ºåˆ—æ¨¡æ¿ç”Ÿæˆã€æ•°æ®å¤„ç†å’ŒLLMå¡«å……çš„å®Œæ•´æµç¨‹ ğŸ†•

### æ–‡æ¡£è¯´æ˜
- **README_AI_OPERATORS.md**: AIæ“ä½œç¬¦è¯¦ç»†ä½¿ç”¨æŒ‡å—
- **README_ANALYTICS.md**: æ•°æ®åˆ†æå’Œå¯è§†åŒ–åŠŸèƒ½è¯¦ç»†æ–‡æ¡£ ğŸ†•
- **README_DATA_COLUMN_PROCESS.md**: æ•°æ®åˆ—å¤„ç†åŠŸèƒ½è¯´æ˜æ–‡æ¡£

æ‰€æœ‰ç¤ºä¾‹è„šæœ¬è¿è¡Œåçš„ç»“æœæ–‡ä»¶ï¼ˆå›¾è¡¨ã€æŠ¥å‘Šã€æ•°æ®ç­‰ï¼‰éƒ½ä¼šç»Ÿä¸€ä¿å­˜åˆ° `output/` ç›®å½•çš„ç›¸åº”å­ç›®å½•ä¸­ï¼Œä¿æŒ `examples/` ç›®å½•çš„æ•´æ´ã€‚

## æµ‹è¯•

è¿è¡Œæµ‹è¯•å¥—ä»¶ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest test/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest test/test_basic.py -v

# æŸ¥çœ‹æµ‹è¯•è¦†ç›–ç‡
pytest test/ --cov=maestro
```

## è®¸å¯è¯

MIT License